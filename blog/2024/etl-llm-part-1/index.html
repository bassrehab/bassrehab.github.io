<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="R3nPzqP9nO2aTgysGUiU3t-pw3wi1xuUuKVaMrimuck"> <meta name="msvalidate.01" content="04fec5e0d64b1c9bc788e98f81ee2a78"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> (Part 1/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration | subhadip mitra </title> <meta name="author" content="Subhadip Mitra"> <meta name="description" content="Rethinking ETLs - The Power of Large Language Models. Part 1 - Explore traditional algorithms for efficient ETL planning in complex data."> <meta name="keywords" content="subhadip, subhadip mitra, subhadeep mitra, subhadip google, google, dikku, personal website, Data Analytics, Quantum Computing, Distributed Systems, Blockchain, Artificial Intelligence, Big Data, ETL Processes, Data Management, Open Source Projects, Technology Blogging, Software Engineering Insights, Data &amp; Analytics Trends, Personal Technology Musings, Approximate Calculations, Quantum Data Management, Real-Time Data Processing, Data Platform Innovations, Cloud Technologies, Machine Learning Models, Technology Consulting"> <meta property="og:site_name" content="subhadip mitra"> <meta property="og:type" content="article"> <meta property="og:title" content="subhadip mitra | (Part 1/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration"> <meta property="og:url" content="https://subhadipmitra.com/blog/2024/etl-llm-part-1/"> <meta property="og:description" content="Rethinking ETLs - The Power of Large Language Models. Part 1 - Explore traditional algorithms for efficient ETL planning in complex data."> <meta property="og:image" content="/assets/img/social_preview.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="(Part 1/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration"> <meta name="twitter:description" content="Rethinking ETLs - The Power of Large Language Models. Part 1 - Explore traditional algorithms for efficient ETL planning in complex data."> <meta name="twitter:image" content="/assets/img/social_preview.png"> <meta name="twitter:site" content="@bassrehab"> <meta name="twitter:creator" content="@bassrehab"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Subhadip Mitra"
        },
        "url": "https://subhadipmitra.com/blog/2024/etl-llm-part-1/",
        "@type": "BlogPosting",
        "description": "Rethinking ETLs - The Power of Large Language Models. Part 1 - Explore traditional algorithms for efficient ETL planning in complex data.",
        "headline": "(Part 1/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration",
        
        "sameAs": ["https://www.researchgate.net/profile/Subhadip-Mitra-3", "https://github.com/bassrehab", "https://www.linkedin.com/in/subhadip-mitra", "https://twitter.com/bassrehab"],
        
        "name": "Subhadip Mitra",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?058310854f7b3c920f894a1d42c3c47b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://subhadipmitra.com/blog/2024/etl-llm-part-1/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> subhadip mitra </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/search/">search</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/contact/">contact</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/license/">licenses</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/privacy/">privacy</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">(Part 1/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration</h1> <p class="post-meta"> April 15, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> algorithms</a>   <a href="/blog/tag/genai"> <i class="fa-solid fa-hashtag fa-sm"></i> genai</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/data"> <i class="fa-solid fa-hashtag fa-sm"></i> data</a>   <a href="/blog/tag/code"> <i class="fa-solid fa-hashtag fa-sm"></i> code</a>     ·   <a href="/blog/category/algorithms"> <i class="fa-solid fa-tag fa-sm"></i> algorithms</a>   <a href="/blog/category/genai"> <i class="fa-solid fa-tag fa-sm"></i> genai</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Part 1: Searching for an Optimal Algorithm for ETL planning</strong></p> <p>Welcome to the first installment of our three-part series exploring the transformative impact of Large Language Models (LLMs) on ETL (Extract, Transform, Load) processes. In this opening segment, we focus on the search for an optimal algorithm for ETL planning.</p> <p>As businesses increasingly rely on vast amounts of data to make critical decisions, the efficiency and effectiveness of ETL processes become paramount. Traditional methods often fall short in handling the complexity and scale of modern data environments, necessitating a shift towards more sophisticated tools.</p> <p>In this part, we delve into how traditional algorithms can be used to design the planning stage of ETL workflows — we identify algorithms that are not only more efficient but also capable of handling complex, dynamic data scenarios. We will explore the foundational concepts behind these algorithms and discuss how they can be tailored to improve the entire data transformation and integration cycle.</p> <p>Join us as we begin our journey into rethinking ETLs with the power of advanced language models, setting the stage for a deeper dive into practical applications and optimization strategies in the subsequent parts of the series.</p> <p><br></p> <h2 id="understanding-the-problem">Understanding the Problem</h2> <p>Before diving into algorithms, let’s clarify the core elements:</p> <ul> <li> <strong>Input Dataset</strong>: The structure (schema), data types, size, and potential quality issues of your initial data source.</li> <li> <strong>Output Dataset</strong>: The desired structure, data types, and any specific formatting requirements for your target data.</li> <li> <strong>ETL Operations</strong>: The available transformations at your disposal (e.g., cleaning, filtering, joining, aggregation, calculations).</li> </ul> <p><br></p> <h2 id="core-algorithm-considerations">Core Algorithm Considerations</h2> <p>Here’s a foundational outline of the algorithm, which we’ll refine for optimality:</p> <ol> <li> <p><strong>Graph Construction:</strong></p> <ul> <li>Represent datasets as nodes.</li> <li>Possible ETL operations define the potential edges between nodes.</li> </ul> </li> <li> <p><strong>Cost Assignment:</strong></p> <ul> <li>Associate a cost with each ETL operation. Costs can incorporate:</li> <li>Computational Complexity: Time and resource usage of the operation.</li> <li>Data Volume impact: How the operation changes dataset size.</li> <li>Dependencies: Operations that must precede others.</li> </ul> </li> <li> <p><strong>Search/Optimization:</strong></p> <ul> <li>Employ a search algorithm to find the path with the lowest cumulative cost from Start to End Node. Consider:</li> <li>Dijkstra’s Algorithm: Suited for finding the shortest overall path.</li> <li>A Search:* Incorporates heuristics (estimates of cost-to-goal) for potential speedups.</li> <li>Genetic Algorithms: Explore a broader search space, potentially finding unconventional but less costly solutions.</li> </ul> </li> </ol> <p><br></p> <h2 id="optimization-refinements">Optimization Refinements</h2> <ul> <li> <strong>Dynamic Cost Adjustment</strong>: Costs aren’t static. Refine cost estimates during execution based on the actual characteristics of intermediate datasets.</li> <li> <strong>Caching and Materialization</strong>: If certain intermediary datasets are reused frequently, strategically store them to avoid recalculation.</li> <li> <strong>Parallelism</strong>: Leverage parallel processing in your ETL tool where possible to execute multiple operations simultaneously.</li> <li> <strong>Constraints</strong>: Factor in constraints like deadlines, resource limits, or error-tolerance thresholds.</li> </ul> <p><br> <br></p> <p><strong>Algorithm Pseudocode (Illustrative)</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
  <span class="n">function</span> <span class="nf">plan_ETL_steps</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">output_dataset</span><span class="p">,</span> <span class="n">available_operations</span><span class="p">):</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="nf">create_graph</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">output_dataset</span><span class="p">,</span> <span class="n">available_operations</span><span class="p">)</span>
    <span class="nf">assign_costs</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

    <span class="n">optimal_path</span> <span class="o">=</span> <span class="nf">dijkstra_search</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">end_node</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">optimal_path</span>

</code></pre></div></div> <p><br></p> <h4 id="step-1-define-the-graphnode-class">Step 1: Define the GraphNode Class</h4> <p>We’ll start by defining a simple class for a graph node that includes basic attributes like node name and any additional data that describes the dataset state at that node.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GraphNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>  <span class="c1"># Data can include schema, size, or other relevant details.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">neighbors</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of tuples (neighbor_node, cost)
</span>
    <span class="k">def</span> <span class="nf">add_neighbor</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">neighbor</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">neighbors</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">neighbor</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">GraphNode(</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span>
</code></pre></div></div> <p><br></p> <h4 id="step-2-edge-representation">Step 2: Edge Representation</h4> <p>The Edges must include multiple costs and a probability for each cost. This would typically involve storing each cost along with its probability in a tuple or a custom object.</p> <p>Multiple costs can represent the computation cost ($) which can have probability in terms of spot-instances of compute available vs committed instances. These computation costs determination can be defined by the priority of the ETL pipeline, e.g. a pipeline / step that generates an end of day compliance report may need a more deterministic behavior and consequently a higher cost for committed computed instances.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">class</span> <span class="nc">Edge</span><span class="p">:</span>
      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">):</span>
          <span class="n">self</span><span class="p">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
          <span class="n">self</span><span class="p">.</span><span class="n">costs</span> <span class="o">=</span> <span class="n">costs</span>  <span class="c1"># List of costs
</span>          <span class="n">self</span><span class="p">.</span><span class="n">probabilities</span> <span class="o">=</span> <span class="n">probabilities</span>  <span class="c1"># List of probabilities for each cost
</span></code></pre></div></div> <p><br></p> <h4 id="step-3-function-to-create-graph-with-intermediate-nodes">Step 3: Function to Create Graph with Intermediate Nodes</h4> <p>This function simulates the creation of intermediate nodes based on hypothetical operations. Each operation affects the dataset, potentially creating a new node:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_graph</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">output_dataset</span><span class="p">,</span> <span class="n">available_operations</span><span class="p">):</span>
    <span class="n">start_node</span> <span class="o">=</span> <span class="nc">GraphNode</span><span class="p">(</span><span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">)</span>
    <span class="n">end_node</span> <span class="o">=</span> <span class="nc">GraphNode</span><span class="p">(</span><span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">,</span> <span class="n">output_dataset</span><span class="p">)</span>
    <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>

    <span class="c1"># Placeholder for a more sophisticated operations processing
</span>    <span class="n">current_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_node</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">operation</span> <span class="ow">in</span> <span class="n">available_operations</span><span class="p">:</span>
        <span class="n">new_nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">current_nodes</span><span class="p">:</span>
            <span class="c1"># Generate a new node for each operation from each current node
</span>            <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">operation</span><span class="p">[</span><span class="sh">'</span><span class="s">apply</span><span class="sh">'</span><span class="p">](</span><span class="n">node</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># Hypothetical function to apply operation
</span>            <span class="n">new_node</span> <span class="o">=</span> <span class="nc">GraphNode</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">node</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s">-&gt;</span><span class="si">{</span><span class="n">operation</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">intermediate_data</span><span class="p">)</span>
            <span class="n">node</span><span class="p">.</span><span class="nf">add_neighbor</span><span class="p">(</span><span class="n">new_node</span><span class="p">,</span> <span class="n">operation</span><span class="p">[</span><span class="sh">'</span><span class="s">cost</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">new_nodes</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>

        <span class="c1"># Update current nodes to the newly created nodes
</span>        <span class="n">current_nodes</span> <span class="o">=</span> <span class="n">new_nodes</span>
        <span class="n">nodes</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">new_nodes</span><span class="p">)</span>

    <span class="c1"># Connect the last set of nodes to the end node
</span>    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">current_nodes</span><span class="p">:</span>
        <span class="n">node</span><span class="p">.</span><span class="nf">add_neighbor</span><span class="p">(</span><span class="n">end_node</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Assuming a nominal cost to reach the end state
</span>
    <span class="k">return</span> <span class="n">start_node</span><span class="p">,</span> <span class="n">end_node</span><span class="p">,</span> <span class="n">nodes</span>

</code></pre></div></div> <p><br></p> <h4 id="step-4-hypothetical-operation-definitions">Step 4: Hypothetical Operation Definitions</h4> <p>To simulate realistic ETL operations, we define each operation with a function that modifies the dataset (simplified for this example):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">apply_cleaning</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">cleaned(</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span>

<span class="k">def</span> <span class="nf">apply_transformation</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">transformed(</span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span>

<span class="n">available_operations</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">clean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">apply</span><span class="sh">'</span><span class="p">:</span> <span class="n">apply_cleaning</span><span class="p">,</span> <span class="sh">'</span><span class="s">cost</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">transform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">apply</span><span class="sh">'</span><span class="p">:</span> <span class="n">apply_transformation</span><span class="p">,</span> <span class="sh">'</span><span class="s">cost</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">]</span>

</code></pre></div></div> <p><br></p> <h4 id="step-5-implementing-a-modified-dijkstras-algorithm">Step 5: Implementing a modified Dijkstra’s Algorithm</h4> <p>Since each edge includes multiple costs with associated probabilities, the comparison of paths becomes probabilistic. We must determine a method to calculate the “expected” cost of a path based on the costs and their probabilities. The expected cost can be computed by summing the products of costs and their corresponding probabilities.</p> <p>We need to redefine the comparison of paths in the priority queue to use these expected values, which involves calculating a composite cost that considers all probabilities.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">heapq</span>

<span class="k">def</span> <span class="nf">calculate_expected_cost</span><span class="p">(</span><span class="n">costs</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sum</span><span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">p</span> <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">costs</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">dijkstra</span><span class="p">(</span><span class="n">start_node</span><span class="p">):</span>
    <span class="c1"># Initialize distances with infinity
</span>    <span class="n">inf</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">infinity</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="n">inf</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">all_nodes</span><span class="p">}</span>
    <span class="n">distances</span><span class="p">[</span><span class="n">start_node</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Priority queue holds tuples of (expected_cost, node)
</span>    <span class="n">priority_queue</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start_node</span><span class="p">)]</span>
    <span class="n">visited</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

    <span class="k">while</span> <span class="n">priority_queue</span><span class="p">:</span>
        <span class="n">current_expected_cost</span><span class="p">,</span> <span class="n">current_node</span> <span class="o">=</span> <span class="n">heapq</span><span class="p">.</span><span class="nf">heappop</span><span class="p">(</span><span class="n">priority_queue</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">current_node</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">visited</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">current_node</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="n">new_expected_cost</span> <span class="o">=</span> <span class="n">current_expected_cost</span> <span class="o">+</span> <span class="nf">calculate_expected_cost</span><span class="p">(</span><span class="n">edge</span><span class="p">.</span><span class="n">costs</span><span class="p">,</span> <span class="n">edge</span><span class="p">.</span><span class="n">probabilities</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_expected_cost</span> <span class="o">&lt;</span> <span class="n">distances</span><span class="p">[</span><span class="n">edge</span><span class="p">.</span><span class="n">target</span><span class="p">]:</span>
                <span class="n">distances</span><span class="p">[</span><span class="n">edge</span><span class="p">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_expected_cost</span>
                <span class="n">heapq</span><span class="p">.</span><span class="nf">heappush</span><span class="p">(</span><span class="n">priority_queue</span><span class="p">,</span> <span class="p">(</span><span class="n">new_expected_cost</span><span class="p">,</span> <span class="n">edge</span><span class="p">.</span><span class="n">target</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">distances</span>

</code></pre></div></div> <p><br> <br></p> <p><strong>Example Execution</strong></p> <p>Here’s we might set up an example run of the above setup:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_dataset</span> <span class="o">=</span> <span class="sh">"</span><span class="s">raw_data</span><span class="sh">"</span>
<span class="n">output_dataset</span> <span class="o">=</span> <span class="sh">"</span><span class="s">final_data</span><span class="sh">"</span>

<span class="n">start_node</span><span class="p">,</span> <span class="n">end_node</span><span class="p">,</span> <span class="n">all_nodes</span> <span class="o">=</span> <span class="nf">create_graph</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">output_dataset</span><span class="p">,</span> <span class="n">available_operations</span><span class="p">)</span>
<span class="n">path</span><span class="p">,</span> <span class="n">cost</span> <span class="o">=</span> <span class="nf">dijkstra_search</span><span class="p">(</span><span class="n">start_node</span><span class="p">,</span> <span class="n">end_node</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Optimal path:</span><span class="sh">"</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Total cost:</span><span class="sh">"</span><span class="p">,</span> <span class="n">cost</span>
</code></pre></div></div> <p>This example demonstrates generating intermediate nodes dynamically as a result of applying operations in an ETL workflow. In a real application, the operations and their impacts would be more complex, involving actual data transformations, schema changes, and potentially conditional logic to decide which operations to apply based on the data’s characteristics or previous processing steps.</p> <p><br></p> <hr> <p><br></p> <h1 id="defining-a-dsl">Defining a DSL</h1> <p>Creating a Domain-Specific Language (DSL) for modeling and specifying ETL (Extract, Transform, Load) processes can greatly simplify designing and implementing complex data workflows, particularly when integrating with a system that dynamically generates an ETL graph as previously discussed. Here’s an outline for a DSL that can describe datasets, operations, and their sequences in an ETL process:</p> <h2 id="dsl-structure-overview">DSL Structure Overview</h2> <p>The DSL will consist of definitions for datasets, operations (transforms and actions), and workflow sequences. Here’s an example of what each component might look like in our DSL:</p> <p><br></p> <h4 id="1-dataset-definitions">1. Dataset Definitions</h4> <p>Datasets are defined by their names and potentially any metadata that describes their schema or other characteristics important for transformations.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="n">raw_data</span> <span class="p">{</span>
    <span class="n">source</span><span class="p">:</span> <span class="sh">"</span><span class="s">path/to/source/file.csv</span><span class="sh">"</span>
    <span class="n">schema</span><span class="p">:</span> <span class="p">{</span><span class="nb">id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">dataset</span> <span class="n">intermediate_data</span> <span class="p">{</span>
    <span class="n">derived_from</span><span class="p">:</span> <span class="n">raw_data</span>
    <span class="n">schema</span><span class="p">:</span> <span class="p">{</span><span class="nb">id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">cleaned_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">dataset</span> <span class="n">final_data</span> <span class="p">{</span>
    <span class="n">derived_from</span><span class="p">:</span> <span class="n">intermediate_data</span>
    <span class="n">schema</span><span class="p">:</span> <span class="p">{</span><span class="nb">id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span> <span class="n">final_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><br></p> <h4 id="2-operation-definitions">2. Operation Definitions</h4> <p>Operations can be transformations or any kind of data processing function. Each operation specifies input and output datasets and may include a cost or complexity rating.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">operation</span> <span class="n">clean_data</span> <span class="p">{</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">raw_data</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">intermediate_data</span>
    <span class="n">cost</span><span class="p">:</span> <span class="mi">2</span>
    <span class="n">function</span><span class="p">:</span> <span class="n">apply_cleaning</span>
<span class="p">}</span>

<span class="n">operation</span> <span class="n">transform_data</span> <span class="p">{</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">intermediate_data</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">final_data</span>
    <span class="n">cost</span><span class="p">:</span> <span class="mi">3</span>
    <span class="n">function</span><span class="p">:</span> <span class="n">apply_transformation</span>
<span class="p">}</span>

</code></pre></div></div> <p><br></p> <h4 id="3-workflow-definition">3. Workflow Definition</h4> <p>A workflow defines the sequence of operations applied to turn raw data into its final form.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">workflow</span> <span class="n">main_etl</span> <span class="p">{</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">raw_data</span>
    <span class="n">end</span><span class="p">:</span> <span class="n">final_data</span>
    <span class="n">steps</span><span class="p">:</span> <span class="p">[</span><span class="n">clean_data</span><span class="p">,</span> <span class="n">transform_data</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div> <p><br></p> <hr> <p><br></p> <h1 id="search-algorithm-selection">Search Algorithm Selection</h1> <p>Let’s dive deeper into how to choose the best search algorithm for planning our ETL process. Recall that our core task involves finding the optimal (likely the lowest cost) path through the graph of datasets and ETL operations. While we defined a modified, Djiktra’s algorithm for variable and probabilistic costs, for discussion below we will use single aggregated weights.</p> <p>Absolutely, let’s dive deeper into how to choose the best search algorithm for planning your ETL process. Recall that our core task involves finding the optimal (likely the lowest cost) path through the graph of datasets and ETL operations.</p> <p><br></p> <iframe width="100%" height="400" src="https://www.youtube.com/embed/A60q6dcoCjw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""> </iframe> <p><br></p> <h2 id="key-search-algorithm-candidates">Key Search Algorithm Candidates</h2> <ol> <li> <p><strong>Dijkstra’s Algorithm</strong>:</p> <ul> <li>Classic shortest path algorithm.</li> <li>Guarantees finding the optimal solution if all edge costs are non-negative.</li> <li>Well-suited when your primary objective is minimizing the overall cumulative cost.</li> <li>Complexity: <code class="language-plaintext highlighter-rouge">O(|V|²)</code> in a simple implementation, but can be improved to <code class="language-plaintext highlighter-rouge">O(|E| + |V|log|V|)</code> using priority queues. <code class="language-plaintext highlighter-rouge">|V| = number of nodes (datasets)</code>, <code class="language-plaintext highlighter-rouge">|E| = number of edges (ETL operations)</code>.</li> </ul> </li> <li> <p><strong>A* Search</strong></p> <ul> <li>Extension of Dijkstra’s that uses a heuristic function to guide the search.</li> <li>Heuristic: An estimate of the cost from a given node to the goal node.</li> <li>Can potentially find solutions faster than Dijkstra’s, especially when good heuristics are available.</li> <li>Complexity: Depends on the quality of the heuristic, but potentially still faster than a purely uninformed search like Dijkstra’s.</li> </ul> </li> <li> <p><strong>Genetic Algorithms</strong></p> <ul> <li>Inspired by evolutionary processes.</li> <li>Maintain a population of potential ETL plans (paths).</li> <li>“Crossover” and “mutation” operations combine and modify plans iteratively, favoring those with lower costs.</li> <li>Excellent for exploring a wider range of solutions and potentially discovering non-intuitive, less costly paths.</li> <li>Complexity: Can be computationally intensive but may find better solutions in complex scenarios.</li> </ul> </li> </ol> <p><br></p> <h2 id="factors-influencing-algorithm-selection">Factors Influencing Algorithm Selection</h2> <ul> <li> <p><strong>Size and Complexity of the ETL Graph</strong>: For smaller graphs, Dijkstra’s might be sufficient. Large, complex graphs might benefit from A* or genetic algorithms.</p> </li> <li> <p><strong>Importance of Optimality</strong>: If guaranteeing the absolute least cost path is critical, Dijkstra’s is the safest bet. If near-optimal solutions are acceptable, A* or genetic algorithms could provide faster results.</p> </li> <li> <p><strong>Availability of Heuristics</strong>: A* search heavily depends on having a good heuristic function. In ETL, a heuristic could estimate the remaining cost based on the types of operations needed to reach the final dataset structure.</p> </li> <li> <p><strong>Resource Constraints</strong>: Genetic algorithms can be computationally expensive. If runtime or available resources are limited, Dijkstra’s or A* might be more practical.</p> </li> </ul> <p><br></p> <h3 id="caveats">Caveats</h3> <ul> <li> <strong>No Perfect Algorithm</strong>: The best algorithm is often problem-specific. Experimentation might be necessary.</li> <li> <strong>Tool Integration</strong>: Our chosen ETL tool might have built-in optimization features or favor certain search algorithms.</li> </ul> <p><br></p> <h2 id="example-heuristic-for-etl">Example: Heuristic for ETL</h2> <p>Imagine your goal is to minimize data volume throughout the process. A heuristic for A* search could be:</p> <ul> <li>Estimate the reduction (or increase) in dataset size caused by the remaining operations needed to reach the final output dataset.</li> </ul> <p><br> <br></p> <p>In the <a href="/blog/2024/etl-llm-part-2/">next iteration of this series</a>, we will walkthrough examples of ETL scenarios, leveraging A* Star algorithm above and explore various optimization goals.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/etl-llm-part-2/">(Part 2/3) Rethinking ETLs - How Large Language Models (LLM) can enhance Data Transformation and Integration</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/genetic-algorithm-inspired-data-platforms-part-1/">Evolutionary Bytes - Harnessing Genetic Algorithms for Smarter Data Platforms (Part 1/2)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/etlc-context-new-paradigm/">Introducing ETL-C (Extract, Transform, Load, Contextualize) - a new data processing paradigm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/genetic-algorithm-inspired-data-platforms-part-2/">Evolutionary Bytes - Harnessing Genetic Algorithms for Smarter Data Platforms (Part 2/2)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/quantum-vs-classical-data-management-complexity/">Quantum vs. Classical - Data Management Computational Complexity</a> </li> <div id="giscus_thread" style="max-width: 1024px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"bassrehab/bassrehab.github.io","data-repo-id":"R_kgDOLvY8Tg","data-category":"Comments","data-category-id":"DIC_kwDOLvY8Ts4CexzE","data-mapping":"title","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Subhadip Mitra. Some Rights Reserved. Last updated: May 19, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-TW7YQ5XPC6"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TW7YQ5XPC6");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>