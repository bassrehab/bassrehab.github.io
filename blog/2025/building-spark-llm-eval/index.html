<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="R3nPzqP9nO2aTgysGUiU3t-pw3wi1xuUuKVaMrimuck"> <meta name="msvalidate.01" content="04fec5e0d64b1c9bc788e98f81ee2a78"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned) | Subhadip Mitra </title> <meta name="author" content="Subhadip Mitra"> <meta name="description" content="A deep dive into building distributed LLM evaluation infrastructure that actually scales - architectural decisions, trade-offs, and lessons learned."> <meta name="keywords" content="subhadip-mitra,subhadip,google,google-cloud,data-&amp;-analytics,ai-innovations,enterprise-technology-leadership,digital-transformation,machine-learning-models,cloud-technologies,quantum-computing,technology-consulting,singapore,researcher,llm,genai"> <meta property="og:site_name" content="Subhadip Mitra"> <meta property="og:type" content="article"> <meta property="og:title" content="Subhadip Mitra | Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)"> <meta property="og:url" content="https://subhadipmitra.com/blog/2025/building-spark-llm-eval/"> <meta property="og:description" content="A deep dive into building distributed LLM evaluation infrastructure that actually scales - architectural decisions, trade-offs, and lessons learned."> <meta property="og:image" content="https://subhadipmitra.com/assets/img/og/building-spark-llm-eval.png"> <meta property="og:image:width" content="1200"> <meta property="og:image:height" content="630"> <meta property="og:locale" content="en"> <meta property="og:logo" content="https://subhadipmitra.com/assets/img/prof_pic.jpg"> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)"> <meta name="twitter:description" content="A deep dive into building distributed LLM evaluation infrastructure that actually scales - architectural decisions, trade-offs, and lessons learned."> <meta name="twitter:image" content="https://subhadipmitra.com/assets/img/og/building-spark-llm-eval.png"> <meta property="article:published_time" content="2025-12-15T18:21:35+00:00"> <meta property="article:author" content="Subhadip Mitra"> <meta property="article:tag" content="llm-evaluation"> <meta property="article:tag" content="apache-spark"> <meta property="article:tag" content="databricks"> <meta property="article:tag" content="mlops"> <meta property="article:tag" content="distributed-systems"> <meta property="article:tag" content="statistical-analysis"> <meta property="article:tag" content="llm"> <meta property="article:section" content="MLOps"> <meta property="article:section" content="Distributed Systems"> <meta property="article:section" content="LLM"> <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://subhadipmitra.com/blog/2025/building-spark-llm-eval/"
        },
        "headline": "Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)",
        "description": "A deep dive into building distributed LLM evaluation infrastructure that actually scales - architectural decisions, trade-offs, and lessons learned.",
        "url": "https://subhadipmitra.com/blog/2025/building-spark-llm-eval/",
        "datePublished": "2025-12-15T18:21:35+00:00",
        
        "dateModified": "2025-12-15T18:21:35+00:00",
        
        "wordCount": 2613,
        "timeRequired": "PT14M",
        
        "image": "https://subhadipmitra.com/assets/img/social_preview.png",
        
        
        "keywords": "llm-evaluation, apache-spark, databricks, mlops, distributed-systems, statistical-analysis, llm",
        
        
        "articleSection": "MLOps",
        
        "author": {
            "@type": "Person",
            "name": "Subhadip Mitra",
            "url": "https://subhadipmitra.com",
            "jobTitle": "Data and Analytics Manager, Site Lead Southeast Asia",
            "worksFor": {
                "@type": "Organization",
                "name": "Google Cloud"
            },
            "sameAs": [
                "https://linkedin.com/in/subhadip-mitra",
                "https://github.com/bassrehab",
                "https://twitter.com/bassrehab"
            ]
        },
        "publisher": {
            "@type": "Organization",
            "name": "Subhadip Mitra",
            "url": "https://subhadipmitra.com",
            "logo": {
                "@type": "ImageObject",
                "url": "https://subhadipmitra.com/assets/img/prof_pic.jpg"
            }
        },
        "isPartOf": {
            "@type": "Blog",
            "name": "binary breakthroughs",
            "url": "https://subhadipmitra.com/blog/"
        }
        
    }
  </script> <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": [
            {
                "@type": "ListItem",
                "position": 1,
                "name": "Home",
                "item": "https://subhadipmitra.com"
            },
            {
                "@type": "ListItem",
                "position": 2,
                "name": "Blog",
                "item": "https://subhadipmitra.com/blog/"
            },
            
            {
                "@type": "ListItem",
                "position": 3,
                "name": "Mlops",
                "item": "https://subhadipmitra.com/blog/category/mlops"
            },
            {
                "@type": "ListItem",
                "position": 4,
                "name": "Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)",
                "item": "https://subhadipmitra.com/blog/2025/building-spark-llm-eval/"
            }
            
        ]
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&amp;family=Inter+Tight:ital,wght@0,100..900;1,100..900&amp;family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?058310854f7b3c920f894a1d42c3c47b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://subhadipmitra.com/blog/2025/building-spark-llm-eval/"> <script src="/assets/js/theme.js?33a804e644f2507dbddc853404eccc7a"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Subhadip</span> Mitra </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/now/">now </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/contact/">contact</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/reading-list/">reading list</a> <a class="dropdown-item " href="/archive/">archive</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/license/">licenses</a> <a class="dropdown-item " href="/privacy/">privacy</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://upir.subhadipmitra.com" rel="external nofollow noopener" target="_blank">docs: UPIR</a> <a class="dropdown-item " href="https://ai-metacognition-toolkit.subhadipmitra.com/" rel="external nofollow noopener" target="_blank">docs: AI Metacognition</a> <a class="dropdown-item " href="https://symmetry.subhadipmitra.com/" rel="external nofollow noopener" target="_blank">symmetry</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)</h1> <p class="post-meta"> Created on December 15, 2025 by Subhadip Mitra </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm-evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> llm-evaluation</a>   <a href="/blog/tag/apache-spark"> <i class="fa-solid fa-hashtag fa-sm"></i> apache-spark</a>   <a href="/blog/tag/databricks"> <i class="fa-solid fa-hashtag fa-sm"></i> databricks</a>   <a href="/blog/tag/mlops"> <i class="fa-solid fa-hashtag fa-sm"></i> mlops</a>   <a href="/blog/tag/distributed-systems"> <i class="fa-solid fa-hashtag fa-sm"></i> distributed-systems</a>   <a href="/blog/tag/statistical-analysis"> <i class="fa-solid fa-hashtag fa-sm"></i> statistical-analysis</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/mlops"> <i class="fa-solid fa-tag fa-sm"></i> MLOps</a>   <a href="/blog/category/distributed-systems"> <i class="fa-solid fa-tag fa-sm"></i> Distributed Systems</a>   <a href="/blog/category/llm"> <i class="fa-solid fa-tag fa-sm"></i> LLM</a> </p> </header> <div class="audio-reader-container"> <div class="audio-reader-compact"> <button class="audio-trigger" id="audio-trigger" aria-label="Open audio player"> <i class="fas fa-headphones"></i> <span>Listen to article</span> <i class="fas fa-chevron-down audio-trigger-icon"></i> </button> <div class="audio-player-expanded" id="audio-player-expanded"> <div class="audio-player-body"> <div class="audio-info-bar"> <i class="fas fa-info-circle"></i> <span>Browser text-to-speech • Quality varies by device</span> </div> <div class="audio-controls-row"> <button class="audio-btn audio-btn-play" id="tts-play" aria-label="Play"> <i class="fas fa-play"></i> <span id="play-text">Play</span> </button> <button class="audio-btn audio-btn-pause" id="tts-pause" style="display: none;" aria-label="Pause"> <i class="fas fa-pause"></i> <span>Pause</span> </button> <button class="audio-btn audio-btn-stop" id="tts-stop" aria-label="Stop"> <i class="fas fa-stop"></i> </button> <div class="audio-speed-control"> <label for="tts-rate" class="audio-speed-label"> <i class="fas fa-gauge-high"></i> <span id="tts-rate-value">1.0x</span> </label> <input id="tts-rate" type="range" min="0.5" max="2" step="0.1" value="1" class="audio-speed-slider"> </div> </div> <div class="audio-voice-row"> <label for="tts-voice" class="audio-voice-label"> <i class="fas fa-microphone"></i> <span>Voice:</span> </label> <select id="tts-voice" class="audio-voice-select"> <option value="">Loading voices...</option> </select> </div> <div class="audio-progress-section"> <div class="audio-progress-info"> <span><i class="fas fa-circle-notch"></i> Progress</span> <span id="tts-progress">0%</span> </div> <div class="progress" style="height: 4px;"> <div class="progress-bar" id="tts-progress-bar" role="progressbar" style="width: 0%" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div> </div> </div> </div> </div> </div> </div> <style>.audio-reader-container{margin:1.5rem 0;font-family:var(--global-font-family,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,sans-serif)}.audio-reader-compact{position:relative}.audio-trigger{display:inline-flex;align-items:center;gap:.5rem;padding:.5rem 1rem;background:var(--global-code-bg-color,#f8f9fa);border:1px solid var(--global-divider-color,#dee2e6);border-radius:.375rem;color:var(--global-text-color,#212529);font-size:.875rem;font-weight:500;cursor:pointer;transition:all .2s ease;font-family:inherit}.audio-trigger:hover{background:var(--global-bg-color,#fff);border-color:var(--global-theme-color,#0d6efd);color:var(--global-theme-color,#0d6efd);box-shadow:0 .125rem .25rem rgba(0,0,0,0.075)}.audio-trigger i:first-child{font-size:1rem;color:var(--global-theme-color,#0d6efd)}.audio-trigger-icon{font-size:.75rem;margin-left:.25rem;transition:transform .3s ease;color:var(--global-text-color-light,#6c757d)}.audio-trigger.active .audio-trigger-icon{transform:rotate(180deg)}.audio-trigger:focus{outline:2px solid var(--global-theme-color,#0d6efd);outline-offset:2px}.audio-player-expanded{display:none;margin-top:.75rem;background:var(--global-bg-color,#fff);border:1px solid var(--global-divider-color,#dee2e6);border-radius:.5rem;box-shadow:0 .25rem .75rem rgba(0,0,0,0.05);animation:slideDown .3s ease}.audio-player-expanded.show{display:block}@keyframes slideDown{from{opacity:0;transform:translateY(-0.5rem)}to{opacity:1;transform:translateY(0)}}.audio-player-body{padding:1rem}.audio-info-bar{display:flex;align-items:center;gap:.5rem;padding:.625rem .75rem;background:var(--global-code-bg-color,#f8f9fa);border-left:2px solid var(--global-theme-color,#0d6efd);border-radius:.25rem;font-size:.8125rem;color:var(--global-text-color-light,#6c757d);margin-bottom:1rem}.audio-info-bar i{color:var(--global-theme-color,#0d6efd);font-size:.875rem}.audio-controls-row{display:flex;align-items:center;gap:.5rem;margin-bottom:.875rem;flex-wrap:wrap}.audio-btn{display:inline-flex;align-items:center;gap:.375rem;padding:.375rem .875rem;border:1px solid transparent;border-radius:.375rem;font-size:.875rem;font-weight:500;cursor:pointer;transition:all .15s ease;font-family:inherit;color:#fff}.audio-btn i{font-size:.8125rem}.audio-btn span{color:#fff}.audio-btn:hover:not(:disabled){transform:translateY(-1px);box-shadow:0 .125rem .375rem rgba(0,0,0,0.15)}.audio-btn:active:not(:disabled){transform:translateY(0)}.audio-btn:disabled{opacity:.6;cursor:not-allowed}.audio-btn-play{background:var(--global-theme-color,#0d6efd);border-color:var(--global-theme-color,#0d6efd)}.audio-btn-play:hover:not(:disabled){background:color-mix(in srgb,var(--global-theme-color,#0d6efd) 85%,black);border-color:color-mix(in srgb,var(--global-theme-color,#0d6efd) 80%,black)}.audio-btn-play.playing{background:#198754;border-color:#198754}.audio-btn-pause{background:#6c757d;border-color:#6c757d}.audio-btn-pause:hover:not(:disabled){background:#5c636a;border-color:#565e64}.audio-btn-stop{background:transparent;color:#dc3545;border-color:#dc3545;padding:.375rem .625rem}.audio-btn-stop:hover:not(:disabled){background:#dc3545;color:#fff;border-color:#dc3545}.audio-speed-control{display:flex;align-items:center;gap:.5rem;margin-left:auto}.audio-speed-label{display:flex;align-items:center;gap:.375rem;font-size:.8125rem;font-weight:500;color:var(--global-text-color,#212529);margin:0;white-space:nowrap}.audio-speed-label i{color:var(--global-theme-color,#0d6efd);font-size:.875rem}.audio-speed-slider{width:80px;height:4px;-webkit-appearance:none;appearance:none;background:var(--global-divider-color,#dee2e6);border-radius:2px;outline:0}.audio-speed-slider::-webkit-slider-thumb{-webkit-appearance:none;appearance:none;width:14px;height:14px;border-radius:50%;background:var(--global-theme-color,#0d6efd);cursor:pointer;transition:transform .15s ease}.audio-speed-slider::-webkit-slider-thumb:hover{transform:scale(1.2)}.audio-speed-slider::-moz-range-thumb{width:14px;height:14px;border-radius:50%;background:var(--global-theme-color,#0d6efd);border:0;cursor:pointer;transition:transform .15s ease}.audio-speed-slider::-moz-range-thumb:hover{transform:scale(1.2)}.audio-voice-row{display:flex;align-items:center;gap:.75rem;margin-bottom:.875rem}.audio-voice-label{display:flex;align-items:center;gap:.375rem;font-size:.8125rem;font-weight:500;color:var(--global-text-color,#212529);margin:0;white-space:nowrap}.audio-voice-label i{color:var(--global-theme-color,#0d6efd);font-size:.875rem}.audio-voice-select{flex:1;padding:.375rem .75rem;border:1px solid var(--global-divider-color,#dee2e6);border-radius:.375rem;font-size:.8125rem;background:var(--global-bg-color,#fff);color:var(--global-text-color,#212529);cursor:pointer;transition:border-color .15s ease}.audio-voice-select:hover{border-color:var(--global-theme-color,#0d6efd)}.audio-voice-select:focus{outline:0;border-color:var(--global-theme-color,#0d6efd);box-shadow:0 0 0 .2rem rgba(13,110,253,0.25)}.audio-progress-section{margin-top:.75rem;padding-top:.75rem;border-top:1px solid var(--global-divider-color,#e9ecef)}
.audio-progress-info{display:flex;justify-content:space-between;align-items:center;font-size:.8125rem;color:var(--global-text-color-light,#6c757d);margin-bottom:.5rem}.audio-progress-info i{margin-right:.25rem;color:var(--global-theme-color,#0d6efd);font-size:.75rem}.progress{border-radius:2px;overflow:hidden;background:var(--global-divider-color,#e9ecef)}.progress-bar{background:var(--global-theme-color,#0d6efd);transition:width .6s ease}[data-theme="dark"] .audio-trigger,body.dark-mode .audio-trigger{background:rgba(255,255,255,0.05);border-color:var(--global-divider-color,#454545);color:var(--global-text-color,#e9ecef)}[data-theme="dark"] .audio-trigger:hover,body.dark-mode .audio-trigger:hover{background:rgba(255,255,255,0.08)}[data-theme="dark"] .audio-player-expanded,body.dark-mode .audio-player-expanded{background:var(--global-bg-color,#1e1e1e);border-color:var(--global-divider-color,#454545)}[data-theme="dark"] .audio-info-bar,body.dark-mode .audio-info-bar{background:rgba(255,255,255,0.03)}[data-theme="dark"] .audio-voice-select,body.dark-mode .audio-voice-select{background:var(--global-bg-color,#1e1e1e);border-color:var(--global-divider-color,#454545);color:var(--global-text-color,#e9ecef)}[data-theme="dark"] .progress,body.dark-mode .progress{background:rgba(255,255,255,0.1)}@media(max-width:576px){.audio-trigger span{display:none}.audio-controls-row{flex-wrap:wrap}.audio-btn span{display:none}.audio-btn{padding:.5rem .75rem}.audio-btn i{font-size:1rem}.audio-speed-control{width:100%;margin-left:0;margin-top:.5rem}.audio-speed-slider{flex:1}.audio-voice-row{flex-direction:column;align-items:stretch}}@media print{.audio-reader-container{display:none!important}}@media(prefers-reduced-motion:reduce){.audio-trigger,.audio-btn,.progress-bar,.audio-player-expanded{transition:none;animation:none}}</style> <script>
(function() {
  'use strict';
  
  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', init);
  } else {
    init();
  }
  
  function init() {
    if (!('speechSynthesis' in window)) {
      document.querySelector('.audio-reader-container').innerHTML = `
        <div class="audio-reader-compact">
          <div class="alert alert-warning d-flex align-items-center" role="alert" style="font-size: 0.875rem;">
            <i class="fas fa-exclamation-triangle me-2"></i>
            <div>Text-to-speech not supported in this browser.</div>
          </div>
        </div>
      `;
      return;
    }

    const synth = window.speechSynthesis;
    let utterance = null;
    let isPaused = false;
    
    const triggerBtn = document.getElementById('audio-trigger');
    const expandedPlayer = document.getElementById('audio-player-expanded');
    const playBtn = document.getElementById('tts-play');
    const pauseBtn = document.getElementById('tts-pause');
    const stopBtn = document.getElementById('tts-stop');
    const voiceSelect = document.getElementById('tts-voice');
    const rateSlider = document.getElementById('tts-rate');
    const rateValue = document.getElementById('tts-rate-value');
    const progressText = document.getElementById('tts-progress');
    const progressBar = document.getElementById('tts-progress-bar');
    const playText = document.getElementById('play-text');

    const possibleSelectors = [
      '.post-content',
      'article .post-content',
      '.post .post-content',
      'article.post',
      '.post',
      'article',
      'main article',
      'main .container',
      'main',
      '.l-main',
      '.content'
    ];
    
    let articleElement = null;
    for (const selector of possibleSelectors) {
      articleElement = document.querySelector(selector);
      if (articleElement) break;
    }
    
    if (!articleElement) {
      console.warn('Audio Reader: Could not find article content');
      return;
    }
    
    const clonedContent = articleElement.cloneNode(true);
    const elementsToRemove = [
      'pre', 'code', 'script', 'style', 'nav', '.audio-reader-container',
      '.citation', '.giscus', '.utterances', '.navigation', '.pagination',
      '.social', '.share', 'header', 'footer', '.header', '.footer', '.sidebar'
    ];
    
    elementsToRemove.forEach(selector => {
      clonedContent.querySelectorAll(selector).forEach(el => el.remove());
    });
    
    const articleText = clonedContent.innerText
      .replace(/\s+/g, ' ')
      .replace(/\n{3,}/g, '\n\n')
      .trim();
    
    if (!articleText || articleText.length < 100) {
      console.warn('Audio Reader: Article too short');
      return;
    }

    // Toggle player
    triggerBtn.addEventListener('click', function() {
      expandedPlayer.classList.toggle('show');
      this.classList.toggle('active');
      localStorage.setItem('audioPlayerExpanded', expandedPlayer.classList.contains('show'));
    });

    // Load voices
    function loadVoices() {
      const voices = synth.getVoices();
      if (voices.length === 0) {
        setTimeout(loadVoices, 100);
        return;
      }
      
      voiceSelect.innerHTML = '<option value="">Default Voice</option>';
      
      const englishVoices = voices.filter(v => v.lang.startsWith('en'));
      const preferredVoices = englishVoices.filter(v => 
        v.name.includes('Google') || v.name.includes('Microsoft') ||
        v.name.includes('Premium') || v.name.includes('Enhanced') || v.name.includes('Natural')
      );
      const standardEnglishVoices = englishVoices.filter(v => !preferredVoices.includes(v));
      const otherVoices = voices.filter(v => !v.lang.startsWith('en'));
      
      preferredVoices.forEach((voice) => {
        const option = document.createElement('option');
        option.value = voices.indexOf(voice);
        option.textContent = `${voice.name} (${voice.lang})`;
        voiceSelect.appendChild(option);
      });
      
      if (standardEnglishVoices.length > 0) {
        const optgroup = document.createElement('optgroup');
        optgroup.label = 'Other English';
        standardEnglishVoices.forEach((voice) => {
          const option = document.createElement('option');
          option.value = voices.indexOf(voice);
          option.textContent = `${voice.name} (${voice.lang})`;
          optgroup.appendChild(option);
        });
        voiceSelect.appendChild(optgroup);
      }
      
      if (otherVoices.length > 0) {
        const optgroup = document.createElement('optgroup');
        optgroup.label = 'Other Languages';
        otherVoices.forEach((voice) => {
          const option = document.createElement('option');
          option.value = voices.indexOf(voice);
          option.textContent = `${voice.name} (${voice.lang})`;
          optgroup.appendChild(option);
        });
        voiceSelect.appendChild(optgroup);
      }
    }

    loadVoices();
    if (synth.addEventListener) {
      synth.addEventListener('voiceschanged', loadVoices);
    }

    function updateProgress(current, total) {
      const percent = Math.min(100, Math.round((current / total) * 100));
      progressText.textContent = `${percent}%`;
      progressBar.style.width = `${percent}%`;
      progressBar.setAttribute('aria-valuenow', percent);
    }

    function updatePlayButton(isPlaying) {
      const icon = playBtn.querySelector('i');
      if (isPlaying) {
        icon.className = 'fas fa-circle-dot';
        playText.textContent = 'Playing';
        playBtn.classList.add('playing');
      } else {
        icon.className = 'fas fa-play';
        playText.textContent = 'Play';
        playBtn.classList.remove('playing');
      }
    }

    function speak() {
      if (isPaused) {
        synth.resume();
        isPaused = false;
        updatePlayButton(true);
        pauseBtn.style.display = 'inline-flex';
        return;
      }

      synth.cancel();
      utterance = new SpeechSynthesisUtterance(articleText);
      
      if (voiceSelect.value) {
        const voices = synth.getVoices();
        utterance.voice = voices[parseInt(voiceSelect.value)];
      }
      
      utterance.rate = parseFloat(rateSlider.value);
      utterance.pitch = 1;
      utterance.volume = 1;
      
      utterance.onstart = function() {
        updatePlayButton(true);
        pauseBtn.style.display = 'inline-flex';
        playBtn.disabled = false;
      };
      
      utterance.onend = function() {
        updatePlayButton(false);
        pauseBtn.style.display = 'none';
        updateProgress(100, 100);
        setTimeout(() => updateProgress(0, 100), 1000);
      };
      
      utterance.onboundary = function(event) {
        updateProgress(event.charIndex, articleText.length);
      };

      utterance.onerror = function(event) {
        if (event.error !== 'interrupted' && event.error !== 'canceled') {
          alert('Playback error. Try a different voice.');
        }
        updatePlayButton(false);
        pauseBtn.style.display = 'none';
      };

      playBtn.disabled = true;
      synth.speak(utterance);
    }

    function pause() {
      if (synth.speaking && !isPaused) {
        synth.pause();
        isPaused = true;
        const icon = playBtn.querySelector('i');
        icon.className = 'fas fa-play';
        playText.textContent = 'Resume';
        playBtn.classList.remove('playing');
        pauseBtn.style.display = 'none';
      }
    }

    function stop() {
      synth.cancel();
      isPaused = false;
      updatePlayButton(false);
      pauseBtn.style.display = 'none';
      updateProgress(0, 100);
    }

    playBtn.addEventListener('click', speak);
    pauseBtn.addEventListener('click', pause);
    stopBtn.addEventListener('click', stop);
    
    rateSlider.addEventListener('input', function(e) {
      rateValue.textContent = `${parseFloat(e.target.value).toFixed(1)}x`;
    });

    window.addEventListener('beforeunload', function() {
      synth.cancel();
    });

    if (localStorage.getItem('audioPlayerExpanded') === 'true') {
      setTimeout(() => {
        expandedPlayer.classList.add('show');
        triggerBtn.classList.add('active');
      }, 100);
    }
  }
})();
</script> <article class="post-content"> <div id="markdown-content"> <p>This post is a deep dive into building <a href="https://github.com/bassrehab/spark-llm-eval" rel="external nofollow noopener" target="_blank">spark-llm-eval</a>, an open-source framework for running LLM evaluations at scale on Apache Spark. I’ll cover the architectural decisions, trade-offs, and lessons learned along the way.</p> <blockquote> <p><strong>TL;DR:</strong> <code class="language-plaintext highlighter-rouge">pip install spark-llm-eval</code> - Distributed LLM evaluation with statistical rigor, built for Spark/Databricks.</p> </blockquote> <h2 id="the-problem-that-wouldnt-go-away">The Problem That Wouldn’t Go Away</h2> <p>I’ve spent the last few years watching teams struggle with the same problem: how do you actually evaluate LLMs at scale? Not the “run 100 examples on your laptop” scale that works fine for research papers, but the “we have 50 million customer interactions and need statistical confidence in our results” scale that enterprises actually deal with.</p> <p>The tooling landscape is… frustrating. Most evaluation frameworks assume you’re running locally. They collect predictions into memory, compute metrics in pandas, and call it a day. That works until it doesn’t, and when it doesn’t, you’re left duct-taping Spark jobs together with custom metric code that nobody wants to maintain.</p> <p>So I built <a href="https://github.com/bassrehab/spark-llm-eval" rel="external nofollow noopener" target="_blank">spark-llm-eval</a> - a framework designed from the ground up to run natively on Spark. Not “Spark as an afterthought” or “we added a Spark wrapper,” but actually thinking about distributed evaluation as the primary use case.</p> <h2 id="quick-start">Quick Start</h2> <p>Before getting into the weeds, here’s what using the framework actually looks like:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">spark_llm_eval.core.config</span> <span class="kn">import</span> <span class="n">ModelConfig</span><span class="p">,</span> <span class="n">ModelProvider</span>
<span class="kn">from</span> <span class="n">spark_llm_eval.core.task</span> <span class="kn">import</span> <span class="n">EvalTask</span>
<span class="kn">from</span> <span class="n">spark_llm_eval.orchestrator.runner</span> <span class="kn">import</span> <span class="n">run_evaluation</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">llm-eval</span><span class="sh">"</span><span class="p">).</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># Load your eval dataset from Delta Lake
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">my_catalog.eval_datasets.qa_benchmark</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Configure the model
</span><span class="n">model_config</span> <span class="o">=</span> <span class="nc">ModelConfig</span><span class="p">(</span>
    <span class="n">provider</span><span class="o">=</span><span class="n">ModelProvider</span><span class="p">.</span><span class="n">OPENAI</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4o-mini</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">api_key_secret</span><span class="o">=</span><span class="sh">"</span><span class="s">secrets/openai-key</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># Define the evaluation task
</span><span class="n">task</span> <span class="o">=</span> <span class="nc">EvalTask</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">qa-eval-001</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="o">=</span><span class="sh">"</span><span class="s">Answer this question: </span><span class="sh">"</span><span class="p">,</span>
    <span class="n">reference_column</span><span class="o">=</span><span class="sh">"</span><span class="s">expected_answer</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># Run evaluation with metrics
</span><span class="n">result</span> <span class="o">=</span> <span class="nf">run_evaluation</span><span class="p">(</span>
    <span class="n">spark</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">exact_match</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">f1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">bleu</span><span class="sh">"</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Results include confidence intervals
</span><span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">"</span><span class="s">f1</span><span class="sh">"</span><span class="p">])</span>
<span class="c1"># MetricValue(value=0.73, confidence_interval=(0.71, 0.75), ...)
</span></code></pre></div></div> <p>That’s it. The framework handles batching, rate limiting, retries, and statistical computation. Results are automatically logged to MLflow if configured.</p> <h2 id="why-spark-and-why-not-just-use-ray-or-dask">Why Spark? (And Why Not Just Use Ray or Dask?)</h2> <p><a href="https://www.ray.io/" rel="external nofollow noopener" target="_blank">Ray</a> and other newer frameworks get a lot of attention for ML workloads, and they solve real problems. But here’s the practical reality: most enterprises already have significant Spark infrastructure. Their data pipelines run on Spark. Their data engineers know Spark. Their governance and security are built around Spark. If you’re on Databricks, your data is in Delta Lake, your governance is through <a href="https://www.databricks.com/product/unity-catalog" rel="external nofollow noopener" target="_blank">Unity Catalog</a>, and your experiments are tracked in MLflow.</p> <p>Building another evaluation framework that requires spinning up a separate Ray cluster, moving data around, and maintaining yet another piece of infrastructure just didn’t make sense to me. The goal was to meet teams where they are, not where I think they should be.</p> <p>There’s also something to be said for Spark’s maturity around exactly-once semantics, fault tolerance, and integration with data governance tooling. When you’re evaluating models that will make decisions affecting real customers, having audit trails and proper data lineage isn’t optional.</p> <h2 id="how-it-compares">How It Compares</h2> <p>Before diving into the architecture, here’s how spark-llm-eval stacks up against other popular frameworks:</p> <table> <thead> <tr> <th>Feature</th> <th><a href="https://github.com/bassrehab/spark-llm-eval" rel="external nofollow noopener" target="_blank">spark-llm-eval</a></th> <th><a href="https://deepeval.com/" rel="external nofollow noopener" target="_blank">DeepEval</a></th> <th><a href="https://docs.ragas.io/en/stable/" rel="external nofollow noopener" target="_blank">Ragas</a></th> <th><a href="https://www.langchain.com/langsmith/evaluation" rel="external nofollow noopener" target="_blank">LangSmith</a></th> </tr> </thead> <tbody> <tr> <td>Spark-native</td> <td>Yes</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>Distributed execution</td> <td>Native</td> <td>Manual</td> <td>Manual</td> <td>-</td> </tr> <tr> <td>Confidence intervals</td> <td>Built-in</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>Delta Lake integration</td> <td>Yes</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>MLflow tracking</td> <td>Yes</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>Multi-provider inference</td> <td>Yes</td> <td>Yes</td> <td>Yes</td> <td>Yes</td> </tr> <tr> <td>LLM-as-judge</td> <td>Yes</td> <td>Yes</td> <td>Yes</td> <td>Yes</td> </tr> <tr> <td>Agent evaluation</td> <td>Yes</td> <td>Limited</td> <td>-</td> <td>Yes</td> </tr> </tbody> </table> <p><br></p> <p>The key differentiator isn’t any single feature - it’s that spark-llm-eval treats distributed execution and statistical rigor as first-class concerns rather than afterthoughts.</p> <h3 id="vs-databricks-mlflow-genai-eval">vs. Databricks MLflow GenAI Eval</h3> <p>A question that comes up frequently: how does this compare to <a href="https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/" rel="external nofollow noopener" target="_blank">Databricks’ built-in MLflow GenAI evaluation</a>? They solve different problems:</p> <table> <thead> <tr> <th> </th> <th>MLflow GenAI Eval</th> <th>spark-llm-eval</th> </tr> </thead> <tbody> <tr> <td><strong>Primary use case</strong></td> <td>Development evaluation + production trace monitoring</td> <td>Large-scale batch evaluation</td> </tr> <tr> <td><strong>Scale</strong></td> <td>Individual traces / small datasets</td> <td>Millions of examples (Spark-distributed)</td> </tr> <tr> <td><strong>Statistical analysis</strong></td> <td>Point estimates</td> <td>Bootstrap CIs, paired t-tests, McNemar’s, effect sizes</td> </tr> <tr> <td><strong>Model providers</strong></td> <td>Databricks model serving focused</td> <td>Multi-provider (OpenAI, Anthropic, Gemini, vLLM)</td> </tr> <tr> <td><strong>Cost controls</strong></td> <td>Standard</td> <td>Token bucket rate limiting, batching optimization</td> </tr> <tr> <td><strong>Workflow</strong></td> <td>Continuous monitoring, human feedback loops</td> <td>Systematic benchmark sweeps, model comparison</td> </tr> </tbody> </table> <p><br></p> <p><strong>When to use MLflow GenAI Eval:</strong></p> <ul> <li>You’re building an agent or RAG application and want to monitor quality in production</li> <li>You need human feedback collection via the Review App</li> <li>You want to reuse the same judges/scorers across dev and production</li> <li>Your evaluation datasets are small to medium sized</li> </ul> <p><strong>When to use spark-llm-eval:</strong></p> <ul> <li>You need to evaluate against your entire corpus (e.g., 500K customer support tickets)</li> <li>You’re comparing models and need statistical significance with confidence intervals</li> <li>You want to run systematic benchmark sweeps across model versions</li> <li>You need detailed statistical analysis (effect sizes, power analysis, stratified metrics)</li> </ul> <p>They’re complementary - spark-llm-eval uses MLflow for experiment tracking internally. The gap spark-llm-eval fills is: “I have 2M labeled examples in Delta Lake and need to know if Model A is statistically significantly better than Model B.”</p> <h2 id="the-architecture-and-the-trade-offs-i-made">The Architecture (And The Trade-offs I Made)</h2> <p>The core insight behind spark-llm-eval is that LLM evaluation is embarrassingly parallel at the example level, but the aggregation phase requires care. Each example can be scored independently, but computing confidence intervals, running significance tests, and handling stratified metrics requires coordination.</p> <p>Here’s the high-level architecture:</p> <p><br></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/spark-eval-arch-480.webp 480w,/assets/img/blog/spark-eval-arch-800.webp 800w,/assets/img/blog/spark-eval-arch-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/spark-eval-arch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><br></p> <p>Here’s how it breaks down:</p> <h3 id="inference-layer">Inference Layer</h3> <p>The inference layer uses Pandas UDFs with Arrow for efficient batching. Each executor maintains its own connection pool to the LLM provider, with executor-local caching to avoid reinitializing clients for every batch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified view of the batch UDF approach
</span><span class="nd">@pandas_udf</span><span class="p">(</span><span class="n">InferenceOutputSchema</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">inference_udf</span><span class="p">(</span><span class="n">batch_iter</span><span class="p">):</span>
    <span class="n">engine</span> <span class="o">=</span> <span class="nf">get_or_create_engine</span><span class="p">()</span>  <span class="c1"># cached per executor
</span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batch_iter</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">engine</span><span class="p">.</span><span class="nf">infer_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></div> <p>I went back and forth on whether to use mapInPandas or standard Pandas UDFs. Ended up with mapInPandas because it gives more control over batching and memory management when dealing with variable-length LLM responses. The performance difference is negligible for most use cases, but the control matters when you’re hitting rate limits or dealing with particularly long outputs.</p> <h3 id="rate-limiting-the-part-nobody-talks-about">Rate Limiting (The Part Nobody Talks About)</h3> <p>Here’s something that surprised me: rate limiting in a distributed context is genuinely hard. You can’t just use a local token bucket because each executor has its own process. You could use Redis or some external coordinator, but that adds latency and another failure mode.</p> <p>I ended up with a pragmatic solution: per-executor rate limiting with conservative defaults. Each executor gets a fraction of the total rate limit, with some headroom for variance. It’s not optimal - you might leave some capacity on the table - but it’s predictable and doesn’t require external coordination.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Rate limit per executor = total_limit / num_executors * safety_factor
</span><span class="n">executor_limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">requests_per_minute</span> <span class="o">/</span> <span class="n">num_executors</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span>
</code></pre></div></div> <p>The 0.8 factor is a hack, honestly. But it works, and I’ve found that slightly underutilizing your rate limit is better than hitting 429s and having to implement complex retry logic.</p> <h3 id="statistical-rigor">Statistical Rigor</h3> <p>This is where I got a bit obsessive. Most evaluation frameworks give you point estimates - “your model got 73% accuracy” - and call it done. But that number is meaningless without context. Is that 73% from 100 examples or 100,000? What’s the confidence interval? Is the difference between model A at 73% and model B at 71% actually significant, or just noise?</p> <p>spark-llm-eval computes bootstrap confidence intervals by default. For binary metrics like accuracy, you get proper Wilson intervals. For comparing models, you get paired significance tests that account for the fact that you’re testing on the same examples.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span> <span class="o">=</span> <span class="n">runner</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span><span class="p">])</span>
<span class="c1"># MetricValue(
#     value=0.73,
#     confidence_interval=(0.71, 0.75),
#     confidence_level=0.95,
#     standard_error=0.012
# )
</span></code></pre></div></div> <p>I’ve seen too many “we improved the model by 2%” claims that evaporate under proper statistical scrutiny. Baking this into the framework means teams get rigorous results without having to think about it.</p> <h2 id="the-parts-that-were-harder-than-expected">The Parts That Were Harder Than Expected</h2> <h3 id="multi-provider-inference">Multi-Provider Inference</h3> <p>Supporting multiple LLM providers (OpenAI, Anthropic, Google, vLLM) sounds straightforward until you realize each one has its own:</p> <ul> <li>Authentication mechanism</li> <li>Rate limiting behavior</li> <li>Response format</li> <li>Error handling quirks</li> <li>Pricing model</li> </ul> <p>I ended up with a factory pattern for inference engines, but the abstraction is leaky in places. Anthropic’s rate limiting is different from OpenAI’s. Google’s safety filters can reject prompts that work fine elsewhere. vLLM deployments vary wildly in their configuration.</p> <p>The pragmatic solution was to make the abstraction thin and let provider-specific behavior bubble up through configuration rather than trying to hide it. Users need to know they’re hitting OpenAI vs Anthropic anyway for cost and latency reasons.</p> <h3 id="llm-as-judge-evaluation">LLM-as-Judge Evaluation</h3> <p>Using LLMs to evaluate LLM outputs is philosophically weird but practically useful. The challenge is that judge prompts are incredibly sensitive to formatting, and getting consistent results requires more prompt engineering than I’d like to admit.</p> <p>The framework includes a judge abstraction with support for multi-aspect scoring and calibration, but I’m still not entirely happy with it. There’s a fundamental tension between making judges easy to use and making them reliable. The current implementation errs on the side of flexibility at the cost of requiring users to validate their judge prompts carefully.</p> <h3 id="agent-trajectory-evaluation">Agent Trajectory Evaluation</h3> <p>Evaluating multi-turn agent conversations was a late addition, and it shows in places. The challenge is that “correctness” for an agent trajectory is much fuzzier than for single-turn QA. Did the agent achieve the goal? Was it efficient? Did it recover from mistakes?</p> <p>I ended up with a trajectory abstraction that captures actions, observations, and state, with metrics for goal completion, efficiency, and action sequence similarity. It works for the common cases, but agent evaluation is still an open research problem and the framework reflects that uncertainty.</p> <h2 id="performance-at-scale">Performance at Scale</h2> <p>I’ve tested the framework across various cluster configurations. Here are some ballpark numbers to set expectations:</p> <table> <thead> <tr> <th>Dataset Size</th> <th>Cluster Config</th> <th>Time</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td>10K examples</td> <td>4 executors, 4 cores each</td> <td>~15 min</td> <td>Rate-limited by OpenAI</td> </tr> <tr> <td>100K examples</td> <td>8 executors, 8 cores each</td> <td>~2 hours</td> <td>Parallelism helps significantly</td> </tr> <tr> <td>1M examples</td> <td>16 executors, 8 cores each</td> <td>~18 hours</td> <td>Batch inference mode, cached responses</td> </tr> </tbody> </table> <p>The bottleneck is almost always the LLM API, not Spark. With self-hosted vLLM, you can push much higher throughput since you control the rate limits. The framework scales linearly with executors until you hit API limits.</p> <p>Here’s what the Spark job execution looks like for a typical evaluation run:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/spark-history-app-jobs-480.webp 480w,/assets/img/blog/spark-history-app-jobs-800.webp 800w,/assets/img/blog/spark-history-app-jobs-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/spark-history-app-jobs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><br></p> <p>And the MLflow integration captures everything for reproducibility:</p> <p><br></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/mlflow-details-page-metrics-480.webp 480w,/assets/img/blog/mlflow-details-page-metrics-800.webp 800w,/assets/img/blog/mlflow-details-page-metrics-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/mlflow-details-page-metrics.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="what-id-do-differently">What I’d Do Differently</h2> <p>If I were starting over, I’d:</p> <ol> <li> <p><strong>Start with better observability.</strong> I added MLflow integration late, and it shows. Proper experiment tracking should be first-class from day one.</p> </li> <li> <p><strong>Think harder about caching.</strong> The current response caching is file-based and works for most cases, but a proper semantic cache would reduce both cost and latency for repeated evaluations.</p> </li> <li> <p><strong>Build stratification in earlier.</strong> Computing metrics by subgroup (by language, by topic, by user segment) is critical for catching model regressions that hide in aggregate metrics. The current implementation supports it, but it feels bolted on.</p> </li> </ol> <h2 id="the-stuff-that-worked">The Stuff That Worked</h2> <p>On the positive side:</p> <ul> <li> <p><strong>Delta Lake integration</strong> was the right call. Having evaluation results as versioned, queryable tables makes debugging and analysis much easier than JSON files or custom formats.</p> </li> <li> <p><strong>Making statistics non-optional</strong> has saved teams from making bad decisions based on noisy metrics. Even when people grumble about “why do I need confidence intervals,” having them available changes the conversation.</p> </li> <li> <p><strong>Databricks-native deployment</strong> meant teams could go from “I want to evaluate my model” to actually running evaluations in minutes, not days. No separate infrastructure to manage, no data movement, no new permissions to negotiate with IT.</p> </li> </ul> <h2 id="whats-next">What’s Next</h2> <p>The framework is functional, but there’s more I want to build:</p> <ul> <li> <p><strong>Streaming evaluation</strong> - Support for evaluating against live data streams, not just batch datasets. Think continuous monitoring of production model outputs.</p> </li> <li> <p><strong>Semantic caching</strong> - Using embeddings to cache similar prompts and reduce redundant API calls. Could cut costs significantly for iterative evaluation runs.</p> </li> <li> <p><strong>Automated regression detection</strong> - Statistical tests that automatically flag when a new model version degrades on specific subgroups, even if aggregate metrics look fine.</p> </li> <li> <p><strong>Better agent evaluation</strong> - This space is evolving fast. I want to add support for tool-use evaluation, multi-agent scenarios, and longer-horizon task completion metrics.</p> </li> </ul> <p>If any of these resonate with your use case, <a href="https://github.com/bassrehab/spark-llm-eval/issues" rel="external nofollow noopener" target="_blank">open an issue</a> or reach out. Priorities are driven by what people actually need.</p> <h2 id="wrapping-up">Wrapping Up</h2> <p>Building spark-llm-eval reinforced something I keep relearning: the hard part of ML infrastructure isn’t the algorithms, it’s the plumbing. Handling rate limits, managing credentials, dealing with provider-specific quirks, computing proper statistics - none of this is glamorous, but it’s where most teams get stuck.</p> <p>The framework is <a href="https://github.com/bassrehab/spark-llm-eval" rel="external nofollow noopener" target="_blank">open source</a> and available on PyPI (<code class="language-plaintext highlighter-rouge">pip install spark-llm-eval</code>). If you’re doing LLM evaluation at scale on Spark/Databricks, I’d love to hear what works and what doesn’t. The space is evolving fast, and I don’t pretend to have all the answers.</p> <hr> <p><em>Feedback? Find me on <a href="https://github.com/bassrehab" rel="external nofollow noopener" target="_blank">GitHub</a> or open an issue on the repo.</em></p> </div> </article> <div class="citation-section"> <div class="citation-header"> <h3>Citation</h3> <p class="citation-intro">If you found this article useful, please cite it using one of the formats below:</p> </div> <div class="citation-content"> <div class="citation-format"> <h4>APA Format</h4> <div class="citation-text"> <p>Mitra, Subhadip. (2025, December). <em>Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)</em>. Retrieved from https://subhadipmitra.com/blog/2025/building-spark-llm-eval/</p> </div> </div> <div class="citation-format"> <h4>BibTeX Entry</h4> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">mitra2025why-i-built-a-spark-native-llm-evaluation-framework-and-what-i-learned</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">{Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)}</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">{Mitra, Subhadip}</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span>   <span class="p">=</span> <span class="s">{Dec}</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">{https://subhadipmitra.com/blog/2025/building-spark-llm-eval/}</span>
<span class="p">}</span>
</code></pre></div></div> </div> </div> </div> <style>.post-footer-featured{margin-top:6rem;padding-top:0}.newsletter-featured{background:var(--global-card-bg-color,#fff);border:2px solid var(--global-theme-color,#b509ac);border-radius:24px;padding:3rem;margin-bottom:3rem}.showcase-label-newsletter{display:inline-flex;align-items:center;gap:.5rem;font-size:.875rem;letter-spacing:.15em;text-transform:uppercase;color:var(--global-theme-color,#b509ac);font-weight:700;margin-bottom:1rem}.newsletter-featured h2{font-size:2rem;font-weight:900;margin:0 0 1rem 0;letter-spacing:-0.02em;line-height:1.1;color:var(--global-text-color,#000)}.newsletter-featured p{font-size:1.125rem;color:var(--global-text-color-light,#666);margin-bottom:1.5rem;line-height:1.6}.newsletter-form-featured{display:flex;gap:.75rem;margin-bottom:1rem}.newsletter-form-featured input{flex:1;padding:.875rem 1.25rem;background:var(--global-bg-color,#fff);color:var(--global-text-color,#000);border:1px solid var(--global-divider-color,#e5e5e5);border-radius:12px;font-size:1rem;transition:all .3s}.newsletter-form-featured input:focus{outline:0;border-color:var(--global-theme-color,#b509ac);box-shadow:0 0 0 3px rgba(181,9,172,0.1)}.newsletter-form-featured button{padding:.875rem 2rem;background:var(--global-theme-color,#b509ac);color:white;border:0;border-radius:12px;font-weight:700;font-size:1rem;cursor:pointer;transition:all .3s;white-space:nowrap}.newsletter-form-featured button:hover{transform:translateY(-4px);box-shadow:0 12px 40px rgba(181,9,172,0.3)}.newsletter-links{display:flex;gap:1rem;flex-wrap:wrap;align-items:center;font-size:.875rem;color:var(--global-text-color-light,#666)}.newsletter-links a{color:var(--global-theme-color,#b509ac);text-decoration:none;font-weight:600;transition:opacity .3s}.newsletter-links a:hover{opacity:.7}.share-section-featured{text-align:center;padding:2rem 0 3rem 0;border-bottom:1px solid var(--global-divider-color,#e5e5e5)}.share-section-featured .share-label{font-size:.875rem;text-transform:uppercase;letter-spacing:.1em;color:var(--global-text-color-light,#666);font-weight:600;margin-bottom:1.25rem}.share-buttons-featured{display:flex;gap:1rem;justify-content:center;align-items:center}.share-link-featured{display:inline-flex;align-items:center;gap:.5rem;font-weight:600;color:var(--global-text-color,#000);text-decoration:none;font-size:.875rem;padding:.5rem 1rem;background:var(--global-code-bg-color,#f8f9fa);border:1px solid var(--global-divider-color,#e5e5e5);border-radius:8px;transition:all .2s ease;white-space:nowrap;cursor:pointer}.share-link-featured:hover{background:var(--global-theme-color,#b509ac);border-color:var(--global-theme-color,#b509ac);color:white;transform:translateY(-2px)}.share-link-featured:hover svg{fill:white}.share-link-featured svg{width:16px;height:16px;flex-shrink:0;transition:fill .2s ease}.related-posts-section{margin-top:3rem;padding-top:0}.related-posts-section h3{font-size:1.75rem;font-weight:800;margin-bottom:2rem;color:var(--global-text-color,#000);text-align:center}@media(max-width:768px){.newsletter-featured{padding:2rem}.newsletter-featured h2{font-size:1.5rem}.newsletter-form-featured{flex-direction:column}.share-buttons-featured{flex-wrap:wrap;gap:.5rem}}</style> <div class="post-footer-featured"> <div class="newsletter-featured"> <div class="showcase-label-newsletter"> <svg width="16" height="16" viewbox="0 0 24 24" fill="currentColor"> <path d="M12 2l3.09 6.26L22 9.27l-5 4.87 1.18 6.88L12 17.77l-6.18 3.25L7 14.14 2 9.27l6.91-1.01L12 2z"></path> </svg> Strategic Insights </div> <h2>Get More Like This</h2> <p> Join technical leaders from Google, Amazon, and Fortune 500s. Get strategic insights on Data, AI, and Cloud transformation delivered to your inbox. </p> <form class="newsletter-form-featured" action="https://app.loops.so/api/newsletter-form/cm614n2d604nlfy1lfo7vgmo5" method="POST"> <input type="email" name="email" placeholder="your@email.com" required> <button type="submit">Subscribe</button> </form> <div class="newsletter-links"> <span>Free insights • No spam • Unsubscribe anytime</span> <span>•</span> <a href="/archive/">Browse the archive →</a> </div> </div> <div class="share-section-featured"> <div class="share-label">Share This Article</div> <div class="share-buttons-featured"> <a href="https://twitter.com/intent/tweet?text=Why%20I%20Built%20a%20Spark-Native%20LLM%20Evaluation%20Framework%20(And%20What%20I%20Learned)&amp;url=https://subhadipmitra.com/blog/2025/building-spark-llm-eval/&amp;via=bassrehab" class="share-link-featured" target="_blank" rel="noopener noreferrer" title="Share on X"> <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M13.6823 10.6218L20.2391 3H18.6854L12.9921 9.61788L8.44486 3H3.2002L10.0765 13.0074L3.2002 21H4.75404L10.7663 14.0113L15.5685 21H20.8131L13.6819 10.6218H13.6823ZM11.5541 13.0956L10.8574 12.0991L5.31391 4.16971H7.70053L12.1742 10.5689L12.8709 11.5655L18.6861 19.8835H16.2995L11.5541 13.096V13.0956Z"></path> </svg> <span>X</span> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://subhadipmitra.com/blog/2025/building-spark-llm-eval/" class="share-link-featured" target="_blank" rel="noopener noreferrer" title="Share on LinkedIn"> <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path> </svg> <span>LinkedIn</span> </a> <a href="https://www.reddit.com/submit?url=https://subhadipmitra.com/blog/2025/building-spark-llm-eval/&amp;title=Why%20I%20Built%20a%20Spark-Native%20LLM%20Evaluation%20Framework%20(And%20What%20I%20Learned)" class="share-link-featured" target="_blank" rel="noopener noreferrer" title="Share on Reddit"> <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M12 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 0 1-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 0 1 .042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 0 1 4.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 0 1 .14-.197.35.35 0 0 1 .238-.042l2.906.617a1.214 1.214 0 0 1 1.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 0 0-.231.094.33.33 0 0 0 0 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 0 0 .029-.463.33.33 0 0 0-.464 0c-.547.533-1.684.73-2.512.73-.828 0-1.979-.196-2.512-.73a.326.326 0 0 0-.232-.095z"></path> </svg> <span>Reddit</span> </a> <a href="https://news.ycombinator.com/submitlink?u=https://subhadipmitra.com/blog/2025/building-spark-llm-eval/&amp;t=Why%20I%20Built%20a%20Spark-Native%20LLM%20Evaluation%20Framework%20(And%20What%20I%20Learned)" class="share-link-featured" target="_blank" rel="noopener noreferrer" title="Share on Hacker News"> <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M0 0v24h24V0H0zm12.3 12.6l-3.6-7.2H10l2.4 5.1 2.4-5.1h1.3l-3.6 7.2v4.8h-1.2v-4.8z"></path> </svg> <span>HN</span> </a> <a href="mailto:?subject=Why%20I%20Built%20a%20Spark-Native%20LLM%20Evaluation%20Framework%20(And%20What%20I%20Learned)&amp;body=Check%20out%20this%20article:%20https://subhadipmitra.com/blog/2025/building-spark-llm-eval/" class="share-link-featured" title="Share via Email"> <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"></path> </svg> <span>Email</span> </a> <button onclick="copyLinkFeatured('https://subhadipmitra.com/blog/2025/building-spark-llm-eval/')" class="share-link-featured" title="Copy link to clipboard"> <svg class="copy-icon" viewbox="0 0 24 24" fill="currentColor"> <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"></path> </svg> <svg class="check-icon" style="display: none;" viewbox="0 0 24 24" fill="currentColor"> <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path> </svg> <span class="copy-text">Copy</span> <span class="copied-text" style="display: none;">Copied!</span> </button> </div> </div> <div class="related-posts-section"> <h3>Continue Reading</h3> </div> </div> <script>
function copyLinkFeatured(url) {
  navigator.clipboard.writeText(url).then(() => {
    const btn = event.target.closest('button');
    const copyText = btn.querySelector('.copy-text');
    const copiedText = btn.querySelector('.copied-text');
    const copyIcon = btn.querySelector('.copy-icon');
    const checkIcon = btn.querySelector('.check-icon');

    copyText.style.display = 'none';
    copiedText.style.display = 'inline';
    copyIcon.style.display = 'none';
    checkIcon.style.display = 'inline';

    setTimeout(() => {
      copyText.style.display = 'inline';
      copiedText.style.display = 'none';
      copyIcon.style.display = 'inline';
      checkIcon.style.display = 'none';
    }, 2000);
  }).catch(err => {
    console.error('Failed to copy:', err);
    alert('Could not copy link. Please copy manually: ' + url);
  });
}

// Newsletter form handler
(function() {
  const form = document.querySelector('.newsletter-form-featured');
  if (!form) return;

  form.addEventListener('submit', function(event) {
    event.preventDefault();

    const emailInput = form.querySelector('input[name="email"]');
    const submitBtn = form.querySelector('button[type="submit"]');
    const email = emailInput.value;

    // Disable submit button and show loading state
    submitBtn.disabled = true;
    const originalText = submitBtn.textContent;
    submitBtn.textContent = 'Subscribing...';

    // Submit to Loops.so
    const formBody = 'userGroup=&email=' + encodeURIComponent(email);
    fetch(form.action, {
      method: 'POST',
      body: formBody,
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
      },
    })
    .then(res => res.json().then(data => ({ ok: res.ok, data })))
    .then(({ ok, data }) => {
      if (ok) {
        // Success - show confirmation message
        submitBtn.textContent = '✓ Subscribed!';
        submitBtn.style.background = '#22c55e';
        emailInput.value = '';

        // Reset after 3 seconds
        setTimeout(() => {
          submitBtn.textContent = originalText;
          submitBtn.style.background = '';
          submitBtn.disabled = false;
        }, 3000);
      } else {
        // Error from API
        throw new Error(data.message || 'Subscription failed');
      }
    })
    .catch(error => {
      // Show error
      submitBtn.textContent = '✗ Failed';
      submitBtn.style.background = '#ef4444';
      console.error('Newsletter subscription error:', error);

      // Reset after 3 seconds
      setTimeout(() => {
        submitBtn.textContent = originalText;
        submitBtn.style.background = '';
        submitBtn.disabled = false;
      }, 3000);
    });
  });
})();
</script> <style>.related-posts-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(300px,1fr));gap:1.5rem}.related-post-card{background:var(--global-card-bg-color,#fff);border:1px solid var(--global-divider-color,#e5e5e5);border-radius:16px;padding:2rem;transition:all .3s cubic-bezier(0.4,0,0.2,1);position:relative;display:flex;flex-direction:column}.related-post-card:hover{transform:translateY(-4px);box-shadow:0 12px 32px rgba(0,0,0,0.1);border-color:var(--global-theme-color,#b509ac)}.related-post-title{font-size:1.25rem;font-weight:700;line-height:1.3;margin:0 0 .75rem 0;color:var(--global-text-color,#000)}.related-post-title a{color:inherit;text-decoration:none;transition:color .3s}.related-post-title a:hover{color:var(--global-theme-color,#b509ac)}.related-post-meta{font-size:.875rem;color:var(--global-text-color-light,#666);margin-bottom:.75rem}.related-post-excerpt{font-size:.95rem;line-height:1.6;color:var(--global-text-color-light,#666);margin-bottom:1rem;flex-grow:1}.related-post-link{display:inline-flex;align-items:center;gap:.5rem;font-weight:700;color:var(--global-theme-color,#b509ac);text-decoration:none;font-size:.95rem;transition:gap .3s;margin-top:auto}.related-post-link:hover{gap:1rem}.related-post-link svg{width:16px;height:16px;transition:transform .3s}.related-post-link:hover svg{transform:translateX(4px)}.external-link-icon{width:14px;height:14px;opacity:.6;margin-left:.25rem}.no-related-posts{text-align:center;padding:3rem;color:var(--global-text-color-light,#666);font-style:italic}@media(max-width:768px){.related-posts-grid{grid-template-columns:1fr;gap:1rem}.related-post-card{padding:1.5rem}.related-post-title{font-size:1.125rem}}</style> <div class="related-posts-container"> <div class="related-posts-grid"> <article class="related-post-card"> <h4 class="related-post-title"> <a href="/blog/2025/detecting-ai-sandbagging/">I Trained Probes to Catch AI Models Sandbagging</a> </h4> <div class="related-post-meta"> December 20, 2025 • sandbagging </div> <p class="related-post-excerpt">First empirical demonstration of activation-level sandbagging detection. Linear probes achieve 90-96% accuracy across Mistral, Gemma, and Qwen models. Key finding - sandbagging representations are model-specific,...</p> <a href="/blog/2025/detecting-ai-sandbagging/" class="related-post-link"> Read More <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M13.025 1l-2.847 2.828 6.176 6.176h-16.354v3.992h16.354l-6.176 6.176 2.847 2.828 10.975-11z"></path> </svg> </a> </article> <article class="related-post-card"> <h4 class="related-post-title"> <a href="/blog/2025/steering-vectors-agents/">Why Steering Vectors Beat Prompting (And When They Don't)</a> </h4> <div class="related-post-meta"> December 18, 2025 • machine-learning </div> <p class="related-post-excerpt">I tested activation steering on 4 agent behaviors across 3 models. The results surprised me.</p> <a href="/blog/2025/steering-vectors-agents/" class="related-post-link"> Read More <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M13.025 1l-2.847 2.828 6.176 6.176h-16.354v3.992h16.354l-6.176 6.176 2.847 2.828 10.975-11z"></path> </svg> </a> </article> <article class="related-post-card"> <h4 class="related-post-title"> <a href="/blog/2025/mcp-maturity-model/">The MCP Maturity Model: Evaluating Your Multi-Agent Context Strategy</a> </h4> <div class="related-post-meta"> November 19, 2025 • MCP </div> <p class="related-post-excerpt">A practical framework for evaluating your multi-agent context management strategy. From ad-hoc string concatenation to self-evolving context systems - where does your architecture stand?</p> <a href="/blog/2025/mcp-maturity-model/" class="related-post-link"> Read More <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M13.025 1l-2.847 2.828 6.176 6.176h-16.354v3.992h16.354l-6.176 6.176 2.847 2.828 10.975-11z"></path> </svg> </a> </article> <article class="related-post-card"> <h4 class="related-post-title"> <a href="/blog/2025/upir-distributed-systems/">UPIR: What If Distributed Systems Could Write (and Verify) Themselves?</a> </h4> <div class="related-post-meta"> November 15, 2025 • distributed-systems </div> <p class="related-post-excerpt">Lessons from building a framework that automatically generates verified distributed systems - and why I think formal methods, synthesis, and ML need to work together...</p> <a href="/blog/2025/upir-distributed-systems/" class="related-post-link"> Read More <svg viewbox="0 0 24 24" fill="currentColor"> <path d="M13.025 1l-2.847 2.828 6.176 6.176h-16.354v3.992h16.354l-6.176 6.176 2.847 2.828 10.975-11z"></path> </svg> </a> </article> </div> </div> <br> <br> <div class="hyvor-talk-container"> <style>.hyvor-talk-container{margin-top:4rem;padding-top:3rem;border-top:2px solid var(--global-divider-color,#e5e5e5)}.hyvor-talk-header{margin-bottom:2rem;text-align:center}.hyvor-talk-header h3{font-size:1.75rem;font-weight:800;margin-bottom:.5rem;color:var(--global-text-color,#000)}.hyvor-talk-header p{font-size:1rem;color:var(--global-text-color-light,#666);margin:0}</style> <div class="hyvor-talk-header"> <h3>Join the Discussion</h3> <p>Share your thoughts, ask questions, or provide feedback on this article</p> </div> <div id="hyvor-talk-view"></div> <script type="application/javascript">
    var HYVOR_TALK_WEBSITE = 14339;
    var HYVOR_TALK_CONFIG = {
      url: 'https://subhadipmitra.com/blog/2025/building-spark-llm-eval/',
      id: '/blog/2025/building-spark-llm-eval/',
      
      title: 'Why I Built a Spark-Native LLM Evaluation Framework (And What I Learned)',
      
      
      palette: {
        accent: '#b509ac',
        accentText: '#ffffff',
        footerHeader: 'var(--global-text-color)',
        footerHeaderText: 'var(--global-text-color-light)',
        box: 'var(--global-card-bg-color)',
        boxText: 'var(--global-text-color)',
        boxLightText: 'var(--global-text-color-light)',
        backgroundText: 'var(--global-text-color)'
      }
      
    };
  </script> <script async type="application/javascript" src="//talk.hyvor.com/web-api/embed.js"></script> </div> </div> </div> </div> </div> <footer class="modern-footer" role="contentinfo"> <div class="footer-container"> <div class="footer-grid"> <div class="footer-brand"> <h3>Subhadip Mitra</h3> <p> Technical Leader, Inventor, and Researcher building the future of Data &amp; Applied AI. <br>Leading Google Cloud's D&amp;A practice across Southeast Asia. </p> <br> <p><a href="mailto:contact@subhadipmitra.com">contact@subhadipmitra.com</a></p> </div> <div class="footer-section"> <h4>Explore</h4> <ul class="footer-links"> <li><a href="/">About</a></li> <li><a href="/now/">What I'm Doing Now</a></li> <li><a href="/blog/">Blog</a></li> <li><a href="/publications/">Publications</a></li> <li><a href="/repositories/">Repositories</a></li> </ul> </div> <div class="footer-section"> <h4>Connect</h4> <ul class="footer-links"> <li><a href="/contact/">Contact</a></li> <li><a href="mailto:contact@subhadipmitra.com">Email</a></li> <li><a href="https://calendly.com/contact-x9nm/30min" target="_blank" rel="external nofollow noopener">Schedule a Call</a></li> <li><a href="https://linkedin.com/in/subhadip-mitra" target="_blank" rel="external nofollow noopener">LinkedIn</a></li> <li><a href="https://github.com/bassrehab" target="_blank" rel="external nofollow noopener">GitHub</a></li> </ul> </div> </div> <div class="footer-bottom"> <div class="footer-copyright"> © 2025 Subhadip Mitra. Some Rights Reserved. Last updated: December 24, 2025. <span class="footer-utility-links"> <a href="/sitemap.xml" title="Sitemap">Sitemap</a> · <a href="/feed.xml" title="RSS Feed">RSS</a> · <a href="/llms.txt" title="AI Agent Information">LLMs</a> </span> </div> <div class="footer-social"> <a href="https://linkedin.com/in/subhadip-mitra" target="_blank" aria-label="LinkedIn" rel="external nofollow noopener"> <i class="fab fa-linkedin-in"></i> </a> <a href="https://github.com/bassrehab" target="_blank" aria-label="GitHub" rel="external nofollow noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/bassrehab" target="_blank" aria-label="Twitter" rel="external nofollow noopener"> <i class="fab fa-twitter"></i> </a> <a href="mailto:contact@subhadipmitra.com" aria-label="Email"> <i class="fas fa-envelope"></i> </a> </div> </div> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-TW7YQ5XPC6"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-TW7YQ5XPC6');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="/assets/js/newsletter.js?c3d0931971ee96e9df74ba70526c3130"></script> </body> </html>