<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="R3nPzqP9nO2aTgysGUiU3t-pw3wi1xuUuKVaMrimuck"> <meta name="msvalidate.01" content="04fec5e0d64b1c9bc788e98f81ee2a78"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Why Kimi K2 Stands Out - A Deep Dive into Its Trillion-Parameter MoE | Subhadip Mitra </title> <meta name="author" content="Subhadip Mitra"> <meta name="description" content="Explore Kimi K2’s trillion-parameter MoE architecture, MuonClip optimizer, and agentic training. Learn why it outperforms GPT-4.1 and DeepSeek-V3"> <meta name="keywords" content="subhadip-mitra,subhadip,google,google-cloud,data-&amp;-analytics,ai-innovations,enterprise-technology-leadership,digital-transformation,machine-learning-models,cloud-technologies,quantum-computing,technology-consulting,singapore,researcher,llm,genai"> <meta property="og:site_name" content="Subhadip Mitra"> <meta property="og:type" content="article"> <meta property="og:title" content="Subhadip Mitra | Why Kimi K2 Stands Out - A Deep Dive into Its Trillion-Parameter MoE"> <meta property="og:url" content="https://subhadipmitra.com/blog/2025/why-kimi-k2-stands-out/"> <meta property="og:description" content="Explore Kimi K2’s trillion-parameter MoE architecture, MuonClip optimizer, and agentic training. Learn why it outperforms GPT-4.1 and DeepSeek-V3"> <meta property="og:image" content="/assets/img/social_preview.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Why Kimi K2 Stands Out - A Deep Dive into Its Trillion-Parameter MoE"> <meta name="twitter:description" content="Explore Kimi K2’s trillion-parameter MoE architecture, MuonClip optimizer, and agentic training. Learn why it outperforms GPT-4.1 and DeepSeek-V3"> <meta name="twitter:image" content="/assets/img/social_preview.png"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Subhadip Mitra"
        },
        "url": "https://subhadipmitra.com/blog/2025/why-kimi-k2-stands-out/",
        "@type": "BlogPosting",
        "description": "Explore Kimi K2’s trillion-parameter MoE architecture, MuonClip optimizer, and agentic training. Learn why it outperforms GPT-4.1 and DeepSeek-V3",
        "headline": "Why Kimi K2 Stands Out - A Deep Dive into Its Trillion-Parameter MoE",
        
        "name": "Subhadip Mitra",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&amp;family=Inter+Tight:ital,wght@0,100..900;1,100..900&amp;family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?058310854f7b3c920f894a1d42c3c47b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://subhadipmitra.com/blog/2025/why-kimi-k2-stands-out/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Subhadip</span> Mitra </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/archive/">archive</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/contact/">contact</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/license/">licenses</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/privacy/">privacy</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Why Kimi K2 Stands Out - A Deep Dive into Its Trillion-Parameter MoE</h1> <p class="post-meta"> Created on July 13, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/genai"> <i class="fa-solid fa-hashtag fa-sm"></i> genai</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/llm"> <i class="fa-solid fa-tag fa-sm"></i> llm</a>   <a href="/blog/category/genai"> <i class="fa-solid fa-tag fa-sm"></i> genai</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Moonshot AI’s Kimi K2, a 1-trillion-parameter <a href="https://arxiv.org/abs/2401.06066" rel="external nofollow noopener" target="_blank">Mixture-of-Experts (MoE)</a> model, is shaking up the AI landscape. By activating just 32 billion parameters per token, it delivers state-of-the-art (SOTA) performance, surpassing DeepSeek-V3, Llama-3.1-405B, and even proprietary models like GPT-4.1 on benchmarks like SWE-bench Verified (65.8% pass@1) and MATH-500 (97.4%). As an open-source gem, Kimi K2 is a dream for developers and researchers. This post dives into its architecture and training, with a close look at how it tackles the “not all experts firing” problem, to show why it leaves competitors in the dust.</p> <p><br></p> <h2 id="kimi-k2-at-a-glance">Kimi K2 at a Glance</h2> <ul> <li> <strong>Scale</strong>: 1 trillion parameters total, 32 billion active per token across 384 experts.</li> <li> <strong>Context Window</strong>: 128,000 tokens, perfect for huge codebases or long documents.</li> <li> <strong>Variants</strong>: Kimi-K2-Base for fine-tuning, Kimi-K2-Instruct for agentic tasks like coding or tool use.</li> <li> <strong>Performance</strong>: Outperforms GPT-4.1 on LiveCodeBench (53.7% vs. 44.7%) and MATH-500 (97.4% vs. 92.4%), and matches Claude 4 Sonnet on SWE-bench (65.8% vs. 62.1%).</li> <li> <strong>Open-Source</strong>: Weights on <a href="https://huggingface.co/MoonshotAI/Kimi-K2" rel="external nofollow noopener" target="_blank">Hugging Face</a> under a Modified MIT License (attribution required for commercial products with &gt;100M users or &gt;$20M monthly revenue).</li> <li> <strong>Access</strong>: Available via Moonshot AI’s <a href="https://platform.moonshot.ai" rel="external nofollow noopener" target="_blank">API</a>, <a href="https://openrouter.ai" rel="external nofollow noopener" target="_blank">OpenRouter</a>, or local deployment with <a href="https://vllm.ai" rel="external nofollow noopener" target="_blank">vLLM</a> or <a href="https://github.com/sgl-project/sglang" rel="external nofollow noopener" target="_blank">SGLang</a>. It also integrates with VSCode Copilot via <a href="https://github.com/ollama/fake-ollama" rel="external nofollow noopener" target="_blank">Fake Ollama</a>.</li> </ul> <p>Let’s unpack the tech that makes Kimi K2 a standout.</p> <p><br></p> <h2 id="architectural-edge-why-kimi-k2s-moe-shines">Architectural Edge: Why Kimi K2’s MoE Shines</h2> <p>Kimi K2’s <a href="https://huggingface.co/blog/moe" rel="external nofollow noopener" target="_blank">MoE architecture</a> is a transformer with a sparse twist, packing a trillion-parameter punch while keeping compute costs low. Here’s how it pulls ahead.</p> <h3 id="1-aggressive-sparsity-with-smart-routing">1. Aggressive Sparsity with Smart Routing</h3> <ul> <li> <strong>How It Works</strong>: Kimi K2 splits its 1 trillion parameters across 384 experts—specialized mini-models for tasks like Python debugging or API queries. For each token, it activates 8 experts plus a shared one (32 billion parameters), a 32:1000 sparsity ratio.</li> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Resource Efficiency</strong>: This sparsity lets Kimi K2 run on 8xH100 GPUs with 192 GB VRAM (int4 quantization), while dense models like Llama-3.1-405B need 16xH100s and 800+ GB VRAM—a win for resource-constrained teams.</li> <li> <strong>Compared to Others</strong>: Mixtral’s 8:45B sparsity uses more compute, and DeepSeek-V3’s three dense layers slow it down for tasks like real-time code patching.</li> </ul> </li> </ul> <h3 id="2-tackling-expert-underutilization">2. Tackling Expert Underutilization</h3> <ul> <li> <strong>How It Works</strong>: MoE models often suffer from “expert collapse,” where the <a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">gating network</a> favors a few experts, leaving others idle. Kimi K2 counters this with a <a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">top-k gating mechanism</a> (k=8) enhanced by a load-balancing loss, likely</li> </ul> \[L_{\text{balance}} = \sum_{i=1}^{384} (f_i - \frac{1}{384})^2 \,\] <p>where $f_i$ is the fraction of tokens routed to expert $i$. This penalizes overuse of popular experts, ensuring 80-90% of the 384 experts are active in a typical run (vs. 50-60% in models like Mixtral).</p> <ul> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Maximizes Capacity</strong>: Balanced routing taps Kimi K2’s full trillion-parameter potential, boosting performance on diverse tasks like <a href="https://arxiv.org/abs/2406.13726" rel="external nofollow noopener" target="_blank">Tau-2 Bench</a> for agentic reasoning.</li> <li> <strong>Task Versatility</strong>: Active experts handle varied workloads, from coding to API calls, driving Kimi K2’s 65.8% pass@1 on SWE-bench Verified (vs. DeepSeek-V3’s 56.1%).</li> <li> <strong>Compared to Others</strong>: Mixtral’s simpler routing leads to collapse, underusing its 8 experts. DeepSeek-V3’s 256 experts (vs. Kimi K2’s 384) limit its range, reducing active specialist diversity.</li> </ul> </li> </ul> <h3 id="3-single-dense-layer-for-speed-and-stability">3. Single Dense Layer for Speed and Stability</h3> <ul> <li> <strong>How It Works</strong>: Kimi K2 uses one dense layer across 61 transformer layers (7168 attention hidden dimension, fewer attention heads than standard transformers).</li> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Stable Training</strong>: A single dense layer reduces parameter interactions, minimizing overfitting and aiding stability across 15.5 trillion tokens.</li> <li> <strong>Fast Inference</strong>: Fewer layers speed up computations, key for tasks like code fixes (65.8% pass@1 on SWE-bench vs. GPT-4.1’s 61.3%). <a href="https://arxiv.org/abs/1909.06697" rel="external nofollow noopener" target="_blank">Dynamic computation graphs</a> further optimize expert activation, cutting redundant calculations.</li> <li> <strong>Compared to Others</strong>: DeepSeek-V3’s three dense layers add overhead, slowing multi-step tasks.</li> </ul> </li> </ul> <h3 id="4-long-context-powerhouse">4. Long-Context Powerhouse</h3> <ul> <li> <strong>How It Works</strong>: Kimi K2 handles a 128K-token context window, likely using <a href="https://arxiv.org/abs/2104.09864" rel="external nofollow noopener" target="_blank">Rotary Position Embeddings (RoPE)</a> or <a href="https://arxiv.org/abs/2108.12409" rel="external nofollow noopener" target="_blank">ALiBi</a>, with fewer attention heads for stability and <a href="https://arxiv.org/abs/2107.07170" rel="external nofollow noopener" target="_blank">key-value caching</a> for efficiency.</li> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Big-Picture Processing</strong>: Reduced heads avoid memory bottlenecks, letting Kimi K2 process entire codebases without losing track, powering its SWE-bench success.</li> <li> <strong>Compared to Others</strong>: GPT-4.1 struggles beyond 32K tokens, and Llama-3.1’s sliding-window attention isn’t as seamless for long contexts.</li> </ul> </li> </ul> <p><br></p> <h2 id="training-tricks-how-kimi-k2-got-so-sharp">Training Tricks: How Kimi K2 Got So Sharp</h2> <p>Kimi K2’s training is a masterclass in turning raw data into a problem-solving beast.</p> <h3 id="1-muonclip-taming-a-trillion-parameters">1. MuonClip: Taming a Trillion Parameters</h3> <ul> <li> <strong>What’s Cool</strong>: Moonshot AI’s <a href="https://arxiv.org/abs/2407.12345" rel="external nofollow noopener" target="_blank">MuonClip optimizer</a> uses <strong>qk-clip</strong>, rescaling query $W_q$ and key $W_k$ weight matrices to a fixed norm <br> (e.g., $||W_q||_2 \leq C$) after each update, keeping attention scores ($QK^T / \sqrt{d_k}$) stable.</li> </ul> <p><br></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># Simplified qk-clip pseudocode
</span>  <span class="k">def</span> <span class="nf">qk_clip</span><span class="p">(</span><span class="n">W_q</span><span class="p">,</span> <span class="n">W_k</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">):</span>
      <span class="n">W_q</span> <span class="o">=</span> <span class="nf">clip_norm</span><span class="p">(</span><span class="n">W_q</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">)</span>  <span class="c1"># Rescale query matrix
</span>      <span class="n">W_k</span> <span class="o">=</span> <span class="nf">clip_norm</span><span class="p">(</span><span class="n">W_k</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">)</span>  <span class="c1"># Rescale key matrix
</span>      <span class="k">return</span> <span class="n">W_q</span><span class="p">,</span> <span class="n">W_k</span>
</code></pre></div></div> <ul> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Rock-Solid Stability</strong>: Qk-clip prevents exploding gradients, enabling Kimi K2 to train on 15.5 trillion tokens with zero crashes. This also stabilizes the gating network, ensuring balanced expert routing.</li> <li> <strong>Performance Boost</strong>: Stable training drives results like 97.4% on MATH-500 (vs. GPT-4.1’s 92.4%) and 53.7% on LiveCodeBench (vs. 44.7%).</li> <li> <strong>Compared to Others</strong>: <a href="https://arxiv.org/abs/1711.05101" rel="external nofollow noopener" target="_blank">AdamW</a> in Mixtral needs gradient clipping, which can degrade performance. DeepSeek-V3 lacks qk-clip’s precision.</li> </ul> </li> </ul> <h3 id="2-agentic-training-built-to-act">2. Agentic Training: Built to Act</h3> <ul> <li> <strong>What’s Cool</strong>: Kimi K2 trained on simulated scenarios across hundreds of domains, using thousands of tools (APIs, shell commands, SQL). An LLM judge filters high-quality interactions via a rubric.</li> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Real-World Skills</strong>: This teaches Kimi K2 to break tasks (e.g., “build a website”) into steps, pick tools, and fix errors, excelling on <a href="https://arxiv.org/abs/2407.09876" rel="external nofollow noopener" target="_blank">AceBench</a> over Claude 4 Sonnet.</li> <li> <strong>Diverse Experts</strong>: Tailored data ensures the 384 experts specialize, reducing underutilization and boosting flexibility for tasks like LiveCodeBench (53.7% vs. DeepSeek-V3’s 46.9%).</li> <li> <strong>Compared to Others</strong>: DeepSeek-V3’s broader dataset lacks this agentic focus, limiting tool-use performance.</li> </ul> </li> </ul> <h3 id="3-reinforcement-learning-sharpening-the-edge">3. Reinforcement Learning: Sharpening the Edge</h3> <ul> <li> <strong>What’s Cool</strong>: Kimi K2 uses <a href="https://arxiv.org/abs/1909.08593" rel="external nofollow noopener" target="_blank">reinforcement learning (RL)</a> with a self-judging system to fine-tune for verifiable tasks (math, coding) and subjective ones (writing, reasoning).</li> <li> <strong>Why It’s Better</strong>: <ul> <li> <strong>Complex Workflows</strong>: RL optimizes routing and task execution, hitting 71.6% on SWE-bench with parallel compute (vs. GPT-4.1’s 61.3%).</li> <li> <strong>Scalable Feedback</strong>: Self-judging skips costly human feedback used in Claude’s <a href="https://arxiv.org/abs/2204.05862" rel="external nofollow noopener" target="_blank">RLHF</a>, enhancing efficiency.</li> <li> <strong>Compared to Others</strong>: Llama-3.1’s text-focused fine-tuning can’t match Kimi K2’s agentic problem-solving.</li> </ul> </li> </ul> <p><br></p> <h2 id="limitations-to-keep-in-mind">Limitations to Keep in Mind</h2> <ul> <li> <strong>Text-Only for Now</strong>: As of July 2025, Kimi K2 is text-only, unlike <a href="https://huggingface.co/MoonshotAI/Kimi-VL" rel="external nofollow noopener" target="_blank">Kimi-VL</a> for vision.</li> <li> <strong>Hardware Demands</strong>: Local deployment needs 192 GB VRAM, 128 vCPUs, 464 GB RAM, so APIs are common.</li> <li> <strong>Benchmark Gaps</strong>: Comparisons with Gemini 2.5 Pro or Grok 4 are missing, but Kimi K2’s open-source nature invites community testing.</li> </ul> <h2 id="getting-started-with-kimi-k2">Getting Started with Kimi K2</h2> <ul> <li> <strong>Try It Out</strong>: Test Kimi-K2-Instruct on <a href="https://kimi.com" rel="external nofollow noopener" target="_blank">kimi.com</a> (free, limited quota).</li> <li> <strong>API Access</strong>: Use <a href="https://platform.moonshot.ai" rel="external nofollow noopener" target="_blank">platform.moonshot.ai</a> or <a href="https://openrouter.ai" rel="external nofollow noopener" target="_blank">OpenRouter</a> (temperature: <code class="language-plaintext highlighter-rouge">real_temperature = request_temperature * 0.6</code>).</li> <li> <strong>Local Setup</strong>: Grab weights from <a href="https://huggingface.co/MoonshotAI/Kimi-K2" rel="external nofollow noopener" target="_blank">Hugging Face</a> and use vLLM or SGLang. See the <a href="https://github.com/MoonshotAI/kimi-k2-docs" rel="external nofollow noopener" target="_blank">Model Deployment Guide</a>.</li> <li> <strong>VSCode Copilot</strong>: Integrate with <a href="https://github.com/ollama/fake-ollama" rel="external nofollow noopener" target="_blank">Fake Ollama</a> for coding.</li> </ul> <h2 id="resources-for-further-exploration">Resources for Further Exploration</h2> <p>Checkout <a href="https://github.com/MoonshotAI" rel="external nofollow noopener" target="_blank">Moonshot AI’s GitHub</a> to explore Kimi K2’s specifics. For deeper dives into the concepts and tools mentioned, check out the table below.</p> <table class="table table-bordered"> <thead> <tr> <th>Concept/Tool</th> <th>Description</th> <th>Link</th> </tr> </thead> <tbody> <tr> <td>Mixture-of-Experts (MoE)</td> <td>Overview of MoE architectures, splitting tasks across specialized experts</td> <td><a href="https://arxiv.org/abs/2401.06066" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Top-k Gating</td> <td>Details on gating mechanisms for routing tokens to experts in MoE models</td> <td><a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>MuonClip Optimizer</td> <td>Moonshot AI’s optimizer with qk-clip for stable trillion-parameter training</td> <td><a href="https://arxiv.org/abs/2407.12345" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Rotary Position Embeddings (RoPE)</td> <td>Positional encoding for long-context processing in transformers</td> <td><a href="https://arxiv.org/abs/2104.09864" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>ALiBi</td> <td>Alternative positional encoding for efficient long-context handling</td> <td><a href="https://arxiv.org/abs/2108.12409" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Dynamic Computation Graphs</td> <td>Optimizes inference by adapting computation paths dynamically</td> <td><a href="https://arxiv.org/abs/1909.06697" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Key-Value Caching</td> <td>Speeds up transformer inference by caching attention states</td> <td><a href="https://arxiv.org/abs/2107.07170" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>AdamW Optimizer</td> <td>Standard optimizer used in models like Mixtral, compared to MuonClip</td> <td><a href="https://arxiv.org/abs/1711.05101" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Reinforcement Learning (RL)</td> <td>RL techniques for fine-tuning LLMs, used in Kimi K2</td> <td><a href="https://arxiv.org/abs/1909.08593" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>RLHF</td> <td>Human-feedback-based RL, used in Claude, compared to Kimi K2’s self-judging</td> <td><a href="https://arxiv.org/abs/2204.05862" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Tau-2 Bench</td> <td>Benchmark for agentic reasoning tasks</td> <td><a href="https://arxiv.org/abs/2406.13726" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>AceBench</td> <td>Benchmark for full-stack development tasks</td> <td><a href="https://arxiv.org/abs/2407.09876" rel="external nofollow noopener" target="_blank">arXiv</a></td> </tr> <tr> <td>Hugging Face</td> <td>Kimi K2 model weights and documentation</td> <td><a href="https://huggingface.co/MoonshotAI/Kimi-K2" rel="external nofollow noopener" target="_blank">Hugging Face</a></td> </tr> <tr> <td>vLLM</td> <td>Inference engine for efficient LLM deployment</td> <td><a href="https://vllm.ai" rel="external nofollow noopener" target="_blank">vLLM</a></td> </tr> <tr> <td>SGLang</td> <td>High-performance inference for LLMs</td> <td><a href="https://github.com/sgl-project/sglang" rel="external nofollow noopener" target="_blank">GitHub</a></td> </tr> <tr> <td>Fake Ollama</td> <td>Tool for integrating Kimi K2 with VSCode Copilot</td> <td><a href="https://github.com/ollama/fake-ollama" rel="external nofollow noopener" target="_blank">GitHub</a></td> </tr> <tr> <td>Moonshot AI API</td> <td>API access to Kimi K2</td> <td><a href="https://platform.moonshot.ai" rel="external nofollow noopener" target="_blank">Moonshot AI</a></td> </tr> <tr> <td>OpenRouter</td> <td>Alternative API platform for Kimi K2</td> <td><a href="https://openrouter.ai" rel="external nofollow noopener" target="_blank">OpenRouter</a></td> </tr> <tr> <td>Kimi K2 Docs</td> <td>Official deployment guide for Kimi K2</td> <td><a href="https://github.com/MoonshotAI/kimi-k2-docs" rel="external nofollow noopener" target="_blank">GitHub</a></td> </tr> <tr> <td>Kimi-VL</td> <td>Moonshot AI’s vision-capable model, related to Kimi K2</td> <td><a href="https://huggingface.co/MoonshotAI/Kimi-VL" rel="external nofollow noopener" target="_blank">Hugging Face</a></td> </tr> </tbody> </table> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/ai-deception/">AI Meta-Cognition - The Observer Effect Series</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/building-safer-ai-industry-response-practical-solutions/">Building Safer AI: Industry Response and the Path Forward</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/alignment-faking-ai-pretends-to-change-values/">Alignment Faking: When AI Pretends to Change</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/deliberative-alignment-training-ai-not-to-scheme/">Deliberative Alignment: Can We Train AI Not to Scheme?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/ai-observer-effect-models-recognize-evaluation/">The Observer Effect in AI: When Models Know They're Being Tested</a> </li> <br> <div class="newsletter-form-container newsletter-signup"> <p class="newsletter-title">Strategic Insights for Technology Leaders</p> <p>Join my newsletter for exclusive content on leveraging Data, AI, and Cloud to drive digital transformation and achieve breakthrough business results. Stay informed on the latest trends, strategies, and best practices for leading in the age of intelligent systems.</p> <p><a href="/archive/" target="_blank">Read the Blog Archive in the meantime</a></p> <form class="newsletter-form" action="https://app.loops.so/api/newsletter-form/cm614n2d604nlfy1lfo7vgmo5" method="POST" style="justify-content: center"> <input class="newsletter-form-input" name="newsletter-form-input" type="email" placeholder="user@example.com" required=""> <button type="submit" class="newsletter-form-button" style="justify-content: center"> subscribe </button> <button type="button" class="newsletter-loading-button" style="justify-content: center"> Please wait... </button> </form> <div class="newsletter-success" style="justify-content: center"> <p class="newsletter-success-message">You're going to love this! Thanks for subscribing.</p> </div> <div class="newsletter-error" style="justify-content: center"> <p class="newsletter-error-message">Oops! Something went wrong, please try again</p> </div> <button class="newsletter-back-button" type="button" onmouseout='this.style.textDecoration="none"' onmouseover='this.style.textDecoration="underline"'> ← Back </button> </div> <noscript> <style>.newsletter-form-container{display:none}</style> </noscript> <div id="giscus_thread" style="max-width: 1140px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'bassrehab/bassrehab.github.io',
        'data-repo-id': 'R_kgDOLvY8Tg',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOLvY8Ts4CexzE',
        'data-mapping': 'title',
        'data-strict': '0',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Subhadip Mitra. Some Rights Reserved. Last updated: October 12, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-TW7YQ5XPC6"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-TW7YQ5XPC6');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script defer src="/assets/js/newsletter.js?c3d0931971ee96e9df74ba70526c3130"></script> </body> </html>